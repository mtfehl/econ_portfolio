[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Welcome to my portfolio! Here you will find my project work across domains such as public policy, econometrics, game theory, networks, and machine learning. You can explore these projects by topic or by tool, including R, MATLAB, Stata, and Python."
  },
  {
    "objectID": "projects.html#featured-work",
    "href": "projects.html#featured-work",
    "title": "My Portfolio",
    "section": "Featured Work",
    "text": "Featured Work\n\n\n\n\n\n\n\n\n\n\nModeling the Impact: When Data Hits Hard\n\n91 min\n\n\nR\n\nMachine Learning\n\nPublic Policy\n\n\n\nPredicting crash injury severity using penalized classification, kNN, & random forests on NHTSA microdata.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#ongoing-projects",
    "href": "projects.html#ongoing-projects",
    "title": "My Portfolio",
    "section": "Ongoing Projects",
    "text": "Ongoing Projects\n\n\n\n\n\n\n\n\n\n\nSteady States: Finding Balance in a Risky World\n\n1 min\n\n\nMATLAB\n\nNetworks\n\nMarkets\n\nGame Theory\n\n\n\nSimulating resource allocation and risk rationing in a two-agent economy using MATLAB.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#completed-projects",
    "href": "projects.html#completed-projects",
    "title": "My Portfolio",
    "section": "Completed Projects",
    "text": "Completed Projects\n\n\n\n\n\n\n\n\n\n\nModeling the Impact: When Data Hits Hard\n\n91 min\n\n\nR\n\nMachine Learning\n\nPublic Policy\n\n\n\nPredicting crash injury severity using penalized classification, kNN, & random forests on NHTSA microdata.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/causal/causal.html",
    "href": "projects/causal/causal.html",
    "title": "Scaling the financial relief of an expanded safety net",
    "section": "",
    "text": "Intro\nThe 2014 Medicaid expansion in the US….\n\n\nData\ntalk about our data source, cleaning, etc\n\n\n\n\n\n\nNote&gt;&gt;\n\n\n\n\n\nuse \"data/labor_market.dta\", clear\n\n* Run the primary regression\nregress wages education experience i.industry, vce(robust)\n\n* Export the results for the next section\nesttab using \"results/table1.html\", replace\n\n\n\nso what we find is…\n\n\nIdentification Strategy\n\n\n\n\n\n\nNote&gt;&gt;\n\n\n\n\n\nuse \"data/labor_market.dta\", clear\n\n* Run the primary regression\nregress wages education experience i.industry, vce(robust)\n\n* Export the results for the next section\nesttab using \"results/table1.html\", replace\n\n\n\n\n\nResults\n\n\n\n\n\n\nNote&gt;&gt;\n\n\n\n\n\nuse \"data/labor_market.dta\", clear\n\n* Run the primary regression\nregress wages education experience i.industry, vce(robust)\n\n* Export the results for the next section\nesttab using \"results/table1.html\", replace\n\n\n\nwe see that:\n\n\n\n\n\n\nExpansion States\n\n\n\n\n\n\n\nNon-Expansion States\n\n\n\n\n\nin the table, we see numbers:\n\n\n\n\n\nModel 1\nModel 2\n\n\n\n\nweight\n-0.006***\n-0.004***\n\n\n\n(0.001)\n(0.002)\n\n\nlength\n\n-0.083\n\n\n\n\n(0.055)\n\n\nforeign\n\n-1.708\n\n\n\n\n(1.067)\n\n\n_cons\n39.440***\n50.537***\n\n\n\n(1.614)\n(6.246)\n\n\nN\n74\n74\n\n\nR2\n0.652\n0.673\n\n\nadj. R2\n0.647\n0.659\n\n\n\n * p &lt; 0.10, ** p &lt; 0.05, *** p &lt; 0.01\n\nMain Regression Results: The impact of Medicaid expansion on out-of-pocket costs.\n\n\nRobustness Check\n\n\n\n\n\n\nNote&gt;&gt;\n\n\n\n\n\nuse \"data/labor_market.dta\", clear\n\n* Run the primary regression\nregress wages education experience i.industry, vce(robust)\n\n* Export the results for the next section\nesttab using \"results/table1.html\", replace\n\n\n\n\n\nConclusion"
  },
  {
    "objectID": "projects/car_crash/car_crash.html",
    "href": "projects/car_crash/car_crash.html",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "",
    "text": "Abstract:\nWe assess whether routinely collected crash, vehicle and environmental variables can predict driver injury severity in U.S. crash microdata. We frame injury severity as a three-class classification problem (No Injury, Injured, Fatal) and compare penalized multinomial regression and tree-based methods under a leak-safe preprocessing pipeline. A core contribution is disciplined variable construction: we collapse high-cardinality administrative codes into interpretable groups, preserve “unknown/not reported” information when it may be informative, and prevent within-crash leakage via grouped splitting by crash ID. Performance is reported using class-balanced metrics and confusion matrices to reflect the imbalanced nature of severe outcomes."
  },
  {
    "objectID": "projects/car_crash/car_crash.html#prediction-problemidea",
    "href": "projects/car_crash/car_crash.html#prediction-problemidea",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Prediction Problem/Idea",
    "text": "Prediction Problem/Idea\nPredicting injury severity in traffic crashes supports road safety policy, vehicle regulation, and post-crash response. However, severity outcomes reflect heterogeneous mechanisms and strong interactions between driver behavior, vehicle protection, and environmental context.\nIn this project we predict driver-level injury severity using supervised learning. Beyond raw accuracy, we emphasize (i) leak-safe preprocessing, (ii) interpretable and stable feature engineering and (iii) evaluation metrics appropriate for multiclass, imbalanced outcomes.\n\nData Description:\nOur data is sourced from the National Highway Traffic Safety Administration, part of the U.S. Department of Transportation, found at: Check the NHTSA Data. They release yearly public reports on car crash statistics, in which we accessed the 2023 crash data. The dataset (after for filtering on drivers only) has the following dimensions:\n\n\nCode\npaste(\"Observations: \", dim(car_crash_usa)[1],\n      \"Variables: \", dim(car_crash_usa)[2])\n\n\n[1] \"Observations:  57939 Variables:  57\""
  },
  {
    "objectID": "projects/car_crash/car_crash.html#base-filtering",
    "href": "projects/car_crash/car_crash.html#base-filtering",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Base Filtering",
    "text": "Base Filtering\nWe restrict the analysis to drivers only (PER_TYP == 1). This aligns the unit of analysis with the prediction target, avoids mixing occupants with fundamentally different exposure and protection and reduces within-crash dependence introduced by multiple passengers.\n\n\nCode\n# Restrict dataset to drivers only\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  filter(PER_TYP==1)"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#target-analysis-severity",
    "href": "projects/car_crash/car_crash.html#target-analysis-severity",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Target Analysis (Severity)",
    "text": "Target Analysis (Severity)\nINJ_SEV is our outcome variable and records the severity of the injury sustained by the driver in the crash. We recode injury severity into three classes (No Injury, Injured, Fatal) to define a clear multiclass prediction task. Observations with unknown injury severity are removed.\n\n\nCode\n# Visualize distribution of outcome var: INJ_SEV\ncar_crash_usa %&gt;%\n  count(INJ_SEVNAME) %&gt;%\n  ggplot(aes(x = reorder(INJ_SEVNAME, n), y = n)) +\n  geom_col(fill = \"steelblue\", color=\"white\") +\n  coord_flip() +\n  labs(title = \"Distribution of Injury Severity\",\n       x = \"Injury Severity\", y = \"Count\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Filter out Unknown/Missing - set factor levels \ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    INJ_SEV = case_when(\n      INJ_SEV == 4 ~ \"Dead\",\n      INJ_SEV %in% c(1, 2, 3) ~ \"Injured\",\n      INJ_SEV == 0 ~ \"No Injury\",\n      TRUE ~ \"Unknown/Missing\"\n    )\n  ) %&gt;%\n  filter(INJ_SEV != \"Unknown/Missing\") %&gt;%\n  mutate(INJ_SEV = factor(INJ_SEV, levels = c(\"No Injury\", \"Injured\", \"Dead\")))\n\n\nAfter restricting to drivers and recoding injury severity into three classes, the outcome is moderately imbalanced, with fatalities (“Dead”) forming the largest share (~45%), which motivates using stratified splits and class-balanced evaluation metrics.\n\n\nCode\n# Generate the frequency table for the modified inj_sev column\nseverity_counts &lt;- car_crash_usa %&gt;%\n  group_by(INJ_SEV) %&gt;%\n  summarise(\n    Count = n(),\n    Percentage = n() / nrow(car_crash_usa) * 100\n  ) %&gt;%\n  arrange(INJ_SEV)\n\nseverity_counts\n\n\n# A tibble: 3 × 3\n  INJ_SEV   Count Percentage\n  &lt;fct&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 No Injury 17242       30.5\n2 Injured   13777       24.3\n3 Dead      25578       45.2"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#driver",
    "href": "projects/car_crash/car_crash.html#driver",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Driver",
    "text": "Driver\n\nDemographics\n\nAge\nDriver AGE is retained as numeric. Invalid/unreported values are recoded to NA and imputed within the recipe to retain observations without treating missingness as a numeric value.\n\n\nCode\n# First, we label unknown/unreported ages as missings\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    AGE = ifelse(AGE %in% c(998, 999), NA_real_, AGE)\n  )\n\n\n\n\nCode\nsummary(car_crash_usa$AGE) # max age is 103 and youngest age is 7\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   7.00   28.00   40.00   43.12   57.00  103.00     798 \n\n\n\n\nCode\ncar_crash_usa %&gt;%\n  mutate(\n    AGE_GRP = case_when(\n      AGE &lt; 16 ~ \"&lt;16\",\n      AGE &lt;= 24 ~ \"16–24\",\n      AGE &lt;= 34 ~ \"25–34\",\n      AGE &lt;= 44 ~ \"35–44\",\n      AGE &lt;= 54 ~ \"45–54\",\n      AGE &lt;= 64 ~ \"55–64\",\n      AGE &lt;= 74 ~ \"65–74\",\n      AGE &gt;= 75 ~ \"75+\"\n    )\n  ) %&gt;%\n  count(AGE_GRP) %&gt;%\n  ggplot(aes(x = AGE_GRP, y = n, fill=AGE_GRP)) +\n  geom_col() +\n  labs(\n    title = \"Driver Age Distribution (Grouped)\",\n    x = \"Age Group\",\n    y = \"Number of Drivers\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nSex\nWe recode SEX into Male, Female, and Unknown by grouping non-informative codes. This preserves all observations and yields a stable categorical predictor.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    SEX = case_when(\n      SEX == 1 ~ \"Male\",\n      SEX == 2 ~ \"Female\",\n      SEX %in% c(8, 9) ~ \"Unknown\",\n      TRUE ~ \"Unknown\"\n    ) %&gt;%\n      factor(levels = c(\"Male\", \"Female\", \"Unknown\"))\n  )\n\nSEX_COUNTS &lt;- car_crash_usa %&gt;%\n  count(SEX) %&gt;%\n  mutate(Percent = n / sum(n) * 100)\n\nSEX_COUNTS\n\n\n# A tibble: 3 × 3\n  SEX         n Percent\n  &lt;fct&gt;   &lt;int&gt;   &lt;dbl&gt;\n1 Male    41768   73.8 \n2 Female  14063   24.8 \n3 Unknown   766    1.35\n\n\n\n\n\nBehavior\n\nSafety Restraint\nREST_USE is recoded into a three-level factor (restrained, unrestrained, unknown) to reduce sparsity while preserving the primary safety distinction. Injury severity differs markedly across these groups, with unrestrained drivers exhibiting a substantially higher share of fatal outcomes, consistent with expected seatbelt protection effects.\n\n\nCode\n# Categorise into simpler groups.\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    REST_SIMPLE = case_when(\n      REST_USE %in% c(1, 2, 3, 6, 8) ~ \"restrained\",\n      REST_USE == 20                ~ \"unrestrained\",\n      REST_USE %in% c(97, 98, 99)   ~ \"unknown\",\n      TRUE                          ~ \"unknown\"\n    ) %&gt;% factor(levels = c(\"restrained\", \"unrestrained\", \"unknown\"))\n  )\n  car_crash_usa %&gt;% count(REST_SIMPLE, sort = TRUE)\n\n\n# A tibble: 3 × 2\n  REST_SIMPLE      n\n  &lt;fct&gt;        &lt;int&gt;\n1 restrained   33432\n2 unrestrained 17985\n3 unknown       5180\n\n\n\n\nCode\n# Injury severity by restraint use\ncar_crash_usa %&gt;%\n  count(REST_SIMPLE, INJ_SEV) %&gt;%\n  group_by(REST_SIMPLE) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(aes(x = REST_SIMPLE, y = prop, fill = INJ_SEV)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Injury severity distribution by restraint use\",\n    x = NULL,\n    y = \"Proportion\"\n  ) + \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nBAC\nALC_RES encodes both measured blood alcohol concentration (BAC, stored as BAC × 1000) and administrative codes indicating that a test was not performed or the result is unknown. We therefore separate alcohol involvement into two complementary representations: a numeric BAC variable (BAC_VALUE) retained only when a valid measurement exists, and a compact categorical indicator (ALC_SIMPLE) that captures test status and retains an explicit unknown category. Summaries of the original ALC_RES codes are used descriptively to understand reporting patterns, while modeling relies on these simplified representations.\n\n\nCode\n# Keep: numeric BAC when measured + compact indicator for interpretation.\n\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    BAC_VALUE = if_else(ALC_RES &gt;= 0 & ALC_RES &lt; 995, ALC_RES / 1000, NA_real_),\n    ALC_SIMPLE = case_when(\n      ALC_RES &gt;= 0  & ALC_RES &lt; 20   ~ \"negative\",  # BAC &lt; 0.020\n      ALC_RES &gt;= 20 & ALC_RES &lt; 995  ~ \"positive\",  # BAC &gt;= 0.020\n      TRUE                           ~ \"unknown\"    # includes not tested / unknown result codes\n    ) %&gt;% factor(levels = c(\"negative\", \"positive\", \"unknown\"))\n  )\n\n# Average injury severity by original ALC_RES codes\nalc_mean_severity &lt;- car_crash_usa %&gt;%\n  filter(!ALC_RES %in% c(97, 98, 99)) %&gt;%   # drop highest-level unknowns\n  mutate(sev_numeric = as.numeric(INJ_SEV)) %&gt;%\n  group_by(ALC_RES) %&gt;%\n  summarise(\n    Mean_Severity = mean(sev_numeric, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(ALC_RES_NUM = as.numeric(ALC_RES))\n\nggplot(alc_mean_severity, aes(x = ALC_RES_NUM, y = Mean_Severity)) +\n  geom_point(aes(color = Mean_Severity), size = 2) +\n  scale_x_continuous(\n    name = \"Alcohol test result code (ALC_RES)\"\n  ) +\n  scale_y_continuous(\n    breaks = c(1, 2, 3),\n    labels = c(\"No Injury (1)\", \"Injured (2)\", \"Dead (3)\"),\n    limits = c(1, 3),\n    name = \"Average injury severity\"\n  ) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  labs(\n    title = \"Average injury severity by alcohol test outcome code\",\n    caption = \"Measured BAC codes (0–994) represent BAC×1000\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;% \n  select(-BAC_VALUE)\n\n\nAmong cases with a recorded BAC measurement, average injury severity is high, consistent with alcohol testing being more common in severe crashes.\n\n\nDrugs\nDRUGS indicates reported drug involvement for the driver. We use the descriptive labels as a categorical predictor, retaining an explicit unknown category and grouping rare categories into an other level to reduce sparsity and improve model stability.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\nmutate(\nDRUGS = DRUGSNAME %&gt;%\nforcats::fct_explicit_na(na_level = \"Unknown\") %&gt;%\nforcats::fct_lump_min(min = 200, other_level = \"Other\")\n) %&gt;%\nselect(-DRUGSNAME)\n\n# distribution of drugs by category\ncar_crash_usa %&gt;%\ncount(DRUGS, sort = TRUE) %&gt;%\nmutate(pct = n / sum(n) * 100)\n\n\n# A tibble: 4 × 3\n  DRUGS                       n   pct\n  &lt;fct&gt;                   &lt;int&gt; &lt;dbl&gt;\n1 No (drugs not involved) 23880 42.2 \n2 Not Reported            22695 40.1 \n3 Reported as Unknown      5730 10.1 \n4 Yes (drugs involved)     4292  7.58\n\n\n\n\nSeat Position\nThis variable is dropped. After restricting to drivers, seat position has essentially no variation and provides negligible predictive signal."
  },
  {
    "objectID": "projects/car_crash/car_crash.html#vehicle-crash-dynamics",
    "href": "projects/car_crash/car_crash.html#vehicle-crash-dynamics",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Vehicle & Crash Dynamics",
    "text": "Vehicle & Crash Dynamics\n\nVehicle Specs\n\nVehicle Type\nVEH_NO is an administrative index within a crash and carries no substantive information; including it would add arbitrary ordering and could amplify within-crash dependence. VPICMAKENAME and VPICMODELNAME are high-cardinality identifiers that largely proxy for other vehicle characteristics already represented (e.g., body class and weight). To avoid sparsity and instability, we exclude these fields.\nVPICBODYCLASSNAME is collapsed into: passenger_car, suv, truck, motorcycle, other, and unknown. These groups reflect fundamental differences in mass and occupant protection, reduce sparsity, and align with standard road safety categories.\n\n\nCode\n# Injury severity by vehicle body class\nggplot(car_crash_usa, aes(x = BODYCLASS_SIMPLE, fill = factor(INJ_SEV))) +\n  geom_bar(position = \"fill\") +\n  labs(\n    x = \"Vehicle Body Class (Grouped)\",\n    y = \"Proportion\",\n    fill = \"Injury Severity\",\n    title = \"Injury Severity Distribution by Vehicle Body Class\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nMotorcycle crashes show a significantly higher fatality share, while trucks show comparatively lower fatality shares.\n\n\nVehicle Weight\nGVWR is mapped to broad weight classes, retaining Unknown where missing. This captures vehicle mass, a key determinant of crash forces, using stable categories suitable for modeling.\n\n\nCode\n# distribution of vehicles by weight class\np1&lt;-car_crash_usa %&gt;% \n  ggplot(aes(y=WEIGHT, fill=WEIGHT)) +\n  geom_bar() +\n  theme_minimal()+\n  labs(title=\"Vehicle Weight\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n# distribution of inj_sev by weight class\np2&lt;-car_crash_usa %&gt;% \n  ggplot(aes(x=WEIGHT, fill=INJ_SEV)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"Count\", title = \"Injury by Vehicle Weight Class\") +\n  coord_flip()+\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\np1+p2\n\n\n\n\n\n\n\n\n\nLighter vehicle classes exhibit higher fatality shares in the data.\n\n\nTotal Vehicles\nVE_TOTAL records the total number of vehicles involved in the crash. We keep it as a numeric count of vehicles involved in the crash. The variable is interpretable and captures an important mechanism: multi-vehicle crashes may differ systematically from single-vehicle crashes in both impact dynamics and exposure to secondary collisions.\n\n\nCode\n# Outlier check for VE_TOTAL\nx &lt;- car_crash_usa$VE_TOTAL[!is.na(car_crash_usa$VE_TOTAL)]\n\nq1  &lt;- quantile(x, 0.25)\nq3  &lt;- quantile(x, 0.75)\niqr &lt;- q3 - q1\nlower &lt;- q1 - 1.5 * iqr\nupper &lt;- q3 + 1.5 * iqr\n\n# cat(\"Lower fence:\", lower, \"\\n\")\n# cat(\"Upper fence:\", upper, \"\\n\")\ncat(\"Number of outliers:\", sum(x &lt; lower | x &gt; upper), \"\\n\")\n\n\nNumber of outliers: 3484 \n\n\nCode\n# Boxplot for VE_TOTAL\nboxplot(car_crash_usa$VE_TOTAL,\n        main = \"Boxplot of VE_TOTAL\",\n        ylab = \"VE_TOTAL\",\n        col = \"lightblue\")\n\n\n\n\n\n\n\n\n\nCode\n# table(car_crash_usa$VE_TOTAL)\n# sort(table(car_crash_usa$VE_TOTAL), decreasing = TRUE)\n\n\nHigh values are plausible in large pileups and are retained.\n\n\n\nCrash Mechanics\n\nFirst Harmful Event\nThe first harmful event HARM_EV includes many detailed mechanisms. We collapse categories into broader, mechanism-based groups (e.g., other motor vehicle, non-motorist, run-off-road, barrier/guardrail) to stabilize estimates and improve interpretability.\n\n\nCode\n# Recode HARM_EV into broader categories (to reduce number of levels)\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(HARM_EV = as.character(HARM_EVNAME)) %&gt;%\n  mutate(\n    HARM_EV = forcats::fct_collapse(\n      factor(HARM_EV),\n      \"Non-Collision\" = c(\"Rollover/Overturn\", \"Jackknife (harmful to this vehicle)\",\n                          \"Fire/Explosion\", \"Immersion or Partial Immersion\",\n                          \"Injured In Vehicle (Non-Collision)\", \"Other Non-Collision\",\n                          \"Pavement Surface Irregularity (Ruts, Potholes, Grates, etc.)\"),\n      \"Non-Motorist\" = c(\"Pedestrian\", \"Pedalcyclist\", \"Non-Motorist on Personal Conveyance\",\n                         \"Fell/Jumped from Vehicle\", \"Ridden Animal or Animal Drawn Conveyance\"),\n      \"Other Motor Vehicle\" = c(\"Motor Vehicle In-Transport\", \"Parked Motor Vehicle\",\n                                \"Working Motor Vehicle\", \"Motor Vehicle in Motion Outside the Trafficway\",\n                                \"Motor Vehicle In-Transport Strikes or is Struck by Cargo, Persons or Objects Set-in-Motion from/by Another Motor Vehicle In Transport\"),\n      \"Tree/Vegetation\" = c(\"Tree (Standing Only)\", \"Shrubbery\"),\n      \"Utility/Traffic Support\" = c(\"Utility Pole/Light Support\", \"Traffic Sign Support\",\n                                    \"Traffic Signal Support\", \"Post, Pole or Other Supports\"),\n      \"Barrier/Guardrail\" = c(\"Concrete Traffic Barrier\", \"Guardrail Face\", \"Guardrail End\",\n                              \"Cable Barrier\", \"Other Traffic Barrier\",\n                              \"Impact Attenuator/Crash Cushion\"),\n      \"Roadside Structure\" = c(\"Bridge Pier or Support\", \"Bridge Overhead Structure\",\n                               \"Bridge Rail (Includes parapet)\", \"Building\", \"Wall\",\n                               \"Fire Hydrant\", \"Mail Box\", \"Culvert\", \"Fence\"),\n      \"Run-off-Road\" = c(\"Ditch\", \"Embankment\", \"Curb\", \"Ground\", \"Snow Bank\"),\n      \"Other Object\" = c(\"Other Object (not fixed)\", \"Object That Had Fallen From Motor Vehicle In-Transport\",\n                         \"Cargo/Equipment Loss, Shift, or Damage [harmful]\", \"Thrown or Falling Object\",\n                         \"Live Animal\", \"Boulder\"),\n      \"Rail Incident\" = c(\"Railway Vehicle\", \"Road Vehicle on Rails\"),\n      \"Unknown/Other\" = c(\"Harmful Event, Details Not Reported\", \"Other Fixed Object\",\n                          \"Unknown Fixed Object\", \"Unknown Object Not Fixed\",\n                          \"Reported as Unknown\")\n    )\n  ) %&gt;%\n  select(-HARM_EVNAME)\n\n# Count outcomes (ranked by frequency)\ncar_crash_usa %&gt;%\n  count(HARM_EV) %&gt;%\n  arrange(desc(n))\n\n\n# A tibble: 11 × 2\n   HARM_EV                     n\n   &lt;fct&gt;                   &lt;int&gt;\n 1 Other Motor Vehicle     33737\n 2 Non-Motorist             8222\n 3 Run-off-Road             3149\n 4 Non-Collision            2932\n 5 Tree/Vegetation          2541\n 6 Barrier/Guardrail        1789\n 7 Roadside Structure       1603\n 8 Utility/Traffic Support  1571\n 9 Other Object              621\n10 Unknown/Other             321\n11 Rail Incident             111\n\n\n\n\nManner of Collision\nCollision manner MAN_COLL is simplified by merging rare or substantively similar categories. The goal is to preserve the main collision geometries (e.g., angle, front-to-front, front-to-rear) while avoiding sparse levels that destabilize model training.\n\n\nCode\n# 1. Recode MAN_COLL numeric codes to descriptive labels\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    MAN_COLL = as.character(MAN_COLL),\n    MAN_COLL = case_match(\n      MAN_COLL,\n      \"0\"  ~ \"Non-Vehicle Collision\",\n      \"1\"  ~ \"Front-to-Rear\",\n      \"2\"  ~ \"Front-to-Front\",\n      \"6\"  ~ \"Angle\",\n      \"7\"  ~ \"Sideswipe -- Same Direction\",\n      \"8\"  ~ \"Sideswipe -- Opposite Direction\",\n      \"9\"  ~ \"Rear-to-Side\",\n      \"11\" ~ \"Other\",\n      \"98\" ~ \"Unknown\",\n      \"99\" ~ \"Unknown\",\n      .default = \"Other\"\n    ),\n    MAN_COLL = factor(MAN_COLL)\n  )\ncar_crash_usa %&gt;%\n  count(MAN_COLL)%&gt;%\n arrange(desc(n))\n\n\n# A tibble: 9 × 2\n  MAN_COLL                            n\n  &lt;fct&gt;                           &lt;int&gt;\n1 Non-Vehicle Collision           23352\n2 Angle                           14845\n3 Front-to-Front                   8967\n4 Front-to-Rear                    6553\n5 Sideswipe -- Same Direction      1412\n6 Sideswipe -- Opposite Direction   981\n7 Other                             212\n8 Unknown                           208\n9 Rear-to-Side                       67\n\n\n\n\nCode\n# 2. Create binned MAN_COLL variable\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    MAN_COLL_BIN = case_when(\n      MAN_COLL == \"Front-to-Front\" ~ \"Head-on\",\n      MAN_COLL == \"Front-to-Rear\"  ~ \"Rear-end\",\n      str_detect(as.character(MAN_COLL), \"Sideswipe\") ~ \"Sideswipe\",\n      MAN_COLL %in% c(\"Angle\", \"Rear-to-Side\") ~ \"Angle\",\n      MAN_COLL == \"Non-Vehicle Collision\" ~ \"Non-vehicle\",\n      MAN_COLL %in% c(\"Other\", \"Unknown\") ~ \"Other/Unknown\",\n      TRUE ~ \"Other/Unknown\"\n    ),\n    MAN_COLL_BIN = factor(\n      MAN_COLL_BIN,\n      levels = c(\n        \"Rear-end\",\n        \"Sideswipe\",\n        \"Angle\",\n        \"Head-on\",\n        \"Non-vehicle\",\n        \"Other/Unknown\"\n      )\n    )\n  )\n\n\n\n\nTravel Speed\nTravel speed TRAV_SP is retained as a numeric predictor where recorded and set to NA when missing or invalid. We handle missingness and potential nonlinearity within the modeling pipeline (including binned representations used later).\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(TRAV_SP = case_when(\n    TRAV_SP &gt; 997 ~ NA,       # recode to combine unknowns\n    TRUE ~ TRAV_SP))\n\n# dist of trav spd\np1 &lt;- car_crash_usa %&gt;% \n  filter(TRAV_SP &lt; 151) %&gt;% \n  ggplot(aes(x = TRAV_SP)) +\n  # Add a density curve on top\n  geom_density(fill = \"#0000FF20\", color = \"blue\") +\n  # Add the boxplot underneath\n  geom_boxplot(aes(y = -0.005), width = 0.005, fill = \"#0000FF80\") + \n  labs(title = \"Travel Speed Distribution\",\n       x = \"Travel Speed (mph)\",\n       y = \"Density\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# trav_sp by outcome\np2 &lt;- car_crash_usa %&gt;% \n  filter(TRAV_SP &lt; 151) %&gt;% \n  ggplot(aes(x = TRAV_SP, y = INJ_SEV, fill = INJ_SEV)) + \n  geom_boxplot() +\n  labs(\n    title = \"Distribution of Speed by Injury \",\n    x = \"Travel Speed (mph)\",\n    y = \"Injury Severity\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\np1 + p2\n\n\n\n\n\n\n\n\n\nTravel speeds tend to be higher for more severe injury outcomes.\n\n\n\nImpact & Damage\n\nImpact Location\nThe point of impact IMPACT1 is grouped into broad sides (Front, Rear, Left, Right, Top/Under, Non-collision), with all unknown/other codes consolidated to a single level.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    IMPACT1 = case_when(\n      IMPACT1 %in% c(98, 99) ~ \"Unknown\",\n      TRUE ~ IMPACT1NAME\n    ),\n    IMPACT1 = case_when(\n      IMPACT1 %in% c(\"11 Clock Point\", \"12 Clock Point\", \"1 Clock Point\") ~ \"Front\",\n      IMPACT1 %in% c(\"5 Clock Point\", \"6 Clock Point\", \"7 Clock Point\")  ~ \"Rear\",\n      IMPACT1 %in% c(\"2 Clock Point\", \"3 Clock Point\", \"4 Clock Point\") |\n        str_detect(IMPACT1, \"Right\")                                      ~ \"Right\",\n      IMPACT1 %in% c(\"8 Clock Point\", \"9 Clock Point\", \"10 Clock Point\") |\n        str_detect(IMPACT1, \"Left\")                                       ~ \"Left\",\n      IMPACT1 %in% c(\"Top\", \"Undercarriage\")                              ~ \"Top/Under\",\n      str_detect(IMPACT1, \"Non-Collision\")                                ~ \"Non-Collision\",\n      TRUE                                                                ~ \"Other/Unknown\"\n    ) %&gt;% factor(levels = c(\"Front\", \"Rear\", \"Left\", \"Right\",\n                            \"Top/Under\", \"Non-Collision\", \"Other/Unknown\"))\n  ) %&gt;%\n  select(-IMPACT1NAME)\n\n# Compact distribution table (counts + %)\ncar_crash_usa %&gt;%\n  count(IMPACT1) %&gt;%\n  mutate(pct = scales::percent(n / sum(n), accuracy = 0.1))\n\n\n# A tibble: 7 × 3\n  IMPACT1           n pct  \n  &lt;fct&gt;         &lt;int&gt; &lt;chr&gt;\n1 Front         36618 64.7%\n2 Rear           4393 7.8% \n3 Left           5214 9.2% \n4 Right          4364 7.7% \n5 Top/Under       659 1.2% \n6 Non-Collision  2904 5.1% \n7 Other/Unknown  2445 4.3% \n\n\n\n\nCar Damage\nVehicle deformation level DEFORMED is retained as an ordinal proxy for impact severity, with Unknown retained to avoid implicitly dropping non-reported cases.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    DEFORMEDNAME = case_when(\n      DEFORMED %in% c(7, 8, 9) ~ \"Unknown\",\n      TRUE ~ DEFORMEDNAME\n    ),\n    DEFORMED = factor(DEFORMEDNAME)\n  ) %&gt;%\n  select(-DEFORMEDNAME)\n\ncar_crash_usa %&gt;%\n  count(DEFORMED) %&gt;%\n  mutate(prop = round(n/sum(n), 4) * 100)\n\n\n# A tibble: 5 × 3\n  DEFORMED              n  prop\n  &lt;fct&gt;             &lt;int&gt; &lt;dbl&gt;\n1 Disabling Damage  37398 66.1 \n2 Functional Damage  4416  7.8 \n3 Minor Damage       3918  6.92\n4 No Damage           838  1.48\n5 Unknown           10027 17.7 \n\n\n\n\n\nPost-Crash Events\n\nRollover\nROLLOVER is simplified into a binary indicator capturing whether a rollover occurred, with an explicit unknown category retained to preserve missing or unreported cases.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    ROLINLOCNAME = case_when(\n      ROLINLOCNAME %in% c(\"Not Applicable\", \"Unknown\") ~ \"Unknown\",\n      TRUE ~ ROLINLOCNAME\n    ),\n    ROLLOVER = case_when(\n      ROLINLOCNAME == \"Unknown\" ~ 8,   # harmonise unknown rollover coding\n      TRUE ~ ROLLOVER\n    ),\n    ROLLOVER = factor(ROLLOVER)\n  )\n\n# Use rollover location as the final rollover variable and drop the original\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(ROLLOVER = factor(ROLINLOCNAME)) %&gt;%\n  select(-ROLINLOCNAME)\n\n\n\n\nFire\nFIRE_EXP is an indicator for vehicle fire. Retained as a categorical variable with Unknown explicitly preserved where reporting is missing.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    FIRE_EXP_SIMPLE = case_when(\n      FIRE_EXP == 1        ~ \"fire\",\n      FIRE_EXP == 0        ~ \"no_fire\",\n      TRUE                 ~ \"unknown\"\n    ) %&gt;% factor(levels = c(\"no_fire\", \"fire\", \"unknown\"))\n  )\n\ncar_crash_usa %&gt;% \n  count(FIRE_EXP) %&gt;% \n  mutate(prop = round(n/sum(n), 4)*100)\n\n\n# A tibble: 2 × 3\n  FIRE_EXP     n  prop\n     &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1        0 54507 96.3 \n2        1  2090  3.69\n\n\n\n\nAir Bag\nAIR_BAG is simplified to deployed, not_deployed, and unknown. Deployment is correlated with crash severity (high-energy impacts are more likely to deploy airbags), so its association with worse outcomes should be interpreted as reflecting crash intensity as well as protection.\n\n\nCode\n# Injury severity by airbag deployment\ncar_crash_usa %&gt;%\n  count(AIRBAG_SIMPLE, INJ_SEV) %&gt;%\n  group_by(AIRBAG_SIMPLE) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(aes(x = AIRBAG_SIMPLE, y = prop, fill = INJ_SEV)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Injury severity distribution by airbag deployment\",\n    x = NULL,\n    y = \"Proportion\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#environment",
    "href": "projects/car_crash/car_crash.html#environment",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Environment",
    "text": "Environment\n\nTime\n\nHour\nHOUR is treated as cyclical time. Invalid hour codes are set to missing and imputed within the recipe, and we encode hour using sine/cosine transformations so that late-night and early-morning hours are represented as close in feature space.\n\n\nCode\ncar_crash_usa %&gt;%\n  filter(!is.na(HOUR), between(HOUR, 0, 23)) %&gt;%\n  ggplot(aes(x = factor(HOUR, levels = 0:23), fill=\"darkred\")) +\n  geom_bar() +\n  labs(\n    title = \"Distribution of Crash Hour (0–23)\",\n    x = \"Hour of Day\",\n    y = \"Count\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 0, vjust = 0.5),\n        plot.title = element_text(hjust = 0.5),\n        legend.position=\"none\")\n\n\n\n\n\n\n\n\n\nCrash frequency varies systematically over the day, with lower counts overnight and higher incidence during afternoon and early evening periods\n\n\nDay\nDay-of-month DAY shows little systematic structure across the calendar days, so we reduce dimensionality by recoding to day-of-week WEEKDAY. This better captures recurring traffic patterns (weekday commuting vs. weekend travel) while avoiding an arbitrary 1–31 scale.\n\n\n\nLocation\n\nRural/Urban\nFor RUR_URB, We retain a three-level factor (Urban, Rural, Unknown), merging administrative/non-informative codes into Unknown.\n\n\nCode\ncar_crash_usa$RUR_URB  &lt;- factor(car_crash_usa$RUR_URBNAME)\n\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(RUR_URB = case_when(\n  RUR_URB %in% c(\"Not Reported\", \"Trafficway Not in State Inventory\", \"Unknown\") ~ \"Unknown\",\n               TRUE ~ RUR_URB\n  )) %&gt;%\n  select(-RUR_URBNAME)\n\n  car_crash_usa %&gt;%\n    count(RUR_URB)\n\n\n# A tibble: 3 × 2\n  RUR_URB     n\n  &lt;chr&gt;   &lt;int&gt;\n1 Rural   22610\n2 Unknown   368\n3 Urban   33619\n\n\n\n\nRoad Type\nRoadway type ROUTE contains many low-frequency categories. We group route codes into broader road hierarchy categories to reduce sparsity while preserving interpretable differences in speed environment and traffic mix.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    ROUTE = as.character(ROUTE),\n    ROUTE = dplyr::recode(\n      ROUTE,\n      \"0\"  = \"Not Signed\",\n      \"1\"  = \"Interstate\",\n      \"2\"  = \"US Highway\",\n      \"3\"  = \"State Highway\",\n      \"4\"  = \"County\",\n      \"5\"  = \"Township\",\n      \"6\"  = \"Municipal\",\n      \"10\" = \"Parkway/Forest Route\",\n      \"11\" = \"Off-Interstate Business\",\n      \"12\" = \"Secondary Route\",\n      \"13\" = \"BIA\",\n      \"95\" = \"Other\",\n      \"96\" = \"Unknown\",\n      \"99\" = \"Unknown\",\n      .default = \"Unknown\"\n    ),\n    ROUTE = factor(ROUTE)\n  )\n\ncar_crash_usa %&gt;%\n  count(ROUTE, sort = TRUE) %&gt;%\n  ggplot(aes(x = fct_reorder(ROUTE, n), y = n, fill=ROUTE)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Crashes by Route Type\", x = NULL, y = \"Count\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position=\"none\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    ROUTE_grp = case_when(\n      ROUTE %in% c(\"Interstate\", \"US Highway\", \"State Highway\") ~ \"Major highways\",\n      ROUTE %in% c(\"County\", \"Municipal\", \"Township\", \"Secondary Route\") ~ \"Local roads\",\n      ROUTE == \"Not Signed\" ~ \"Not signed\",\n      ROUTE == \"Other\" ~ \"Other\",\n      TRUE ~ \"Unknown\"\n    ),\n    ROUTE_grp = factor(\n      ROUTE_grp,\n      levels = c(\"Major highways\", \"Local roads\", \"Not signed\", \"Other\", \"Unknown\")\n    )\n  )\n\n\n\n\n\nConditions\n\nRoad Conditions\nRoad surface condition VSURCOND is collapsed into a small set of friction-relevant groups (e.g., dry, wet, snow/ice, other/unknown) to reduce sparsity while preserving the primary safety mechanism.\n\n\nCode\n# Collapse roadway surface condition into interpretable groups\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    VSURCOND_SIMPLE = case_when(\n      VSURCOND == 1                     ~ \"dry\",\n      VSURCOND %in% c(2, 3, 4)          ~ \"wet_icy\",   # wet, snow/slush, ice\n      VSURCOND %in% c(8, 9, 0)          ~ \"unknown\",   # other / unknown / not reported\n      TRUE                              ~ \"unknown\"\n    ) %&gt;% factor(levels = c(\"dry\", \"wet_icy\", \"unknown\"))\n  )\n\ncar_crash_usa %&gt;% \n  count(VSURCOND_SIMPLE) %&gt;% \n  mutate(prop = round(n/sum(n), 4)*100)\n\n\n# A tibble: 3 × 3\n  VSURCOND_SIMPLE     n  prop\n  &lt;fct&gt;           &lt;int&gt; &lt;dbl&gt;\n1 dry             47847 84.5 \n2 wet_icy          6737 11.9 \n3 unknown          2013  3.56\n\n\n\n\nLight Condition\nLGT_COND contains detailed and occasionally ambiguous lighting categories. To reduce sparsity and improve interpretability, lighting conditions are recoded into a small set of visibility states. This representation preserves meaningful differences in visibility while yielding stable categories for modeling.\n\n\nCode\n# Recode light condition into a smaller set of interpretable categories\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    LGT_SIMPLE = case_when(\n      LGT_COND == 1 ~ \"daylight\",\n      LGT_COND == 2 ~ \"dark_no_lights\",\n      LGT_COND == 3 ~ \"dark_lit\",\n      LGT_COND == 6 ~ \"dark_unknown\",\n      LGT_COND %in% c(4, 5) ~ \"twilight\",     # dawn + dusk\n      LGT_COND %in% c(7, 8, 9) ~ \"unknown\",   # unknown / not reported\n      TRUE ~ \"unknown\"\n    ) %&gt;% factor(levels = c(\n      \"daylight\", \"dark_no_lights\", \"dark_lit\",\n      \"dark_unknown\", \"twilight\", \"unknown\"\n    ))\n  )\n\n# Distribution check\ncar_crash_usa %&gt;%\n  tabyl(LGT_SIMPLE) %&gt;%\n  adorn_pct_formatting(digits = 2)\n\n\n     LGT_SIMPLE     n percent\n       daylight 28012  49.49%\n dark_no_lights 13913  24.58%\n       dark_lit 11249  19.88%\n   dark_unknown   543   0.96%\n       twilight  2617   4.62%\n        unknown   263   0.46%\n\n\n\n\nWeather\nWEATHER contains detailed and infrequent categories. We collapse it into a small set of mechanism-based groups reflecting visibility and road-surface conditions, with an explicit unknown category retained to improve stability for modeling.\nBecause weather and lighting jointly affect visibility, their interaction is considered later during feature engineering.\n\n\nCode\n# Recode weather into broader categories based on visibility and road conditions\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(\n    WEATHER_SIMPLE = case_when(\n      WEATHER %in% c(1, 10) ~ \"good_visibility\",        # clear, cloudy\n      WEATHER %in% c(2, 3, 4, 5, 12) ~ \"precipitation\", # rain, mist, sleet, snow, freezing rain\n      WEATHER %in% c(6, 7, 8, 11) ~ \"low_visibility\",   # fog, blowing dirt/snow, crosswinds\n      WEATHER %in% c(98, 99) ~ \"unknown\",              # not reported / unknown\n      TRUE ~ \"unknown\"\n    ) %&gt;% factor(levels = c(\n      \"good_visibility\", \"precipitation\",\n      \"low_visibility\", \"unknown\"\n    ))\n  )\n\n# Distribution check post cleaning\ncar_crash_usa %&gt;%\n  tabyl(WEATHER_SIMPLE) %&gt;%\n  adorn_pct_formatting(digits = 2)\n\n\n  WEATHER_SIMPLE     n percent\n good_visibility 49454  87.38%\n   precipitation  5044   8.91%\n  low_visibility   191   0.34%\n         unknown  1908   3.37%\n\n\n\n\nCode\n# Severity composition by weather\ncar_crash_usa %&gt;%\n  count(WEATHER_SIMPLE, INJ_SEV) %&gt;%\n  group_by(WEATHER_SIMPLE) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ggplot(aes(x = WEATHER_SIMPLE, y = prop, fill = INJ_SEV)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Injury severity by weather\", x = NULL, y = \"Proportion\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nSpeed Limit\nPosted speed limit VSPD_LIM is retained as numeric roadway context. We later combine it with travel speed to engineer a speeding indicator (travel speed above posted limit), which is likely more informative than either measure alone.\n\n\nCode\ncar_crash_usa &lt;- car_crash_usa %&gt;%\n  mutate(VSPD_LIM = case_when(\n    VSPD_LIM &gt; 80 ~ NA,\n    TRUE ~ VSPD_LIM))\n\ncar_crash_usa %&gt;% \n  filter(!is.na(VSPD_LIM)) %&gt;% \n  ggplot(aes(x=VSPD_LIM)) +\n  geom_histogram(binwidth = 5, fill = \"#4B9E71\", color = \"white\", boundary = 0) +\n  scale_x_continuous(breaks = seq(0, 80, 5)) + \n  labs(title = \"Distribution of Speed Limit\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5))"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#missingness",
    "href": "projects/car_crash/car_crash.html#missingness",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Missingness",
    "text": "Missingness\nSome predictors are inherently numeric and encode quantitative magnitude rather than discrete states. For such variables, retaining an “Unknown” or “Unreported” category would discard scale information and incorrectly treat non-observation as a meaningful level. We therefore examine the extent and nature of missingness in numeric variables to motivate appropriate imputation strategies. These strategies are implemented later in the recipes stage.\n\n\nCode\n# calculates the % of NAs in every column\nmissing_audit &lt;- car_crash_usa %&gt;%\n  summarise(across(everything(), ~ sum(is.na(.) ) / n() * 100)) %&gt;%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Percent_Missing\") %&gt;%\n  arrange(desc(Percent_Missing)) %&gt;%\n  filter(Percent_Missing &gt; 0)\n\n# visual of the missing data\nggplot(missing_audit, aes(x = reorder(Variable, Percent_Missing), y = Percent_Missing)) +\n  geom_col(fill = \"tomato\") +\n  geom_text(aes(label = paste0(round(Percent_Missing, 1), \"%\")), \n            hjust = -0.2,   \n            size = 3.5) +   \n  coord_flip() +\n  labs(title = \"Percentage of Missing Data by Variable\", \n       y = \"% Missing\", \n       x = \"Variable\") +\n  expand_limits(y = max(missing_audit$Percent_Missing) * 1.1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nTRAV_SP\nTravel speed is missing over 60% of observations. We expect this variable to be a very important predictor for injury severity of a crash; thus, we would like to keep this variable and handle the missing data.\n\n\nCode\n# lets explore the missingness structure of TRAV_SP: with INJ_SEV\ncar_crash_usa %&gt;%\n  group_by(INJ_SEV) %&gt;%\n  summarise(\n    total_obs = n(),\n    missing_trav_sp = sum(is.na(TRAV_SP)),\n    percent_missing = mean(is.na(TRAV_SP)) * 100\n  ) %&gt;%\n  arrange(desc(percent_missing))\n\n\n# A tibble: 3 × 4\n  INJ_SEV   total_obs missing_trav_sp percent_missing\n  &lt;fct&gt;         &lt;int&gt;           &lt;int&gt;           &lt;dbl&gt;\n1 Dead          25578           16978            66.4\n2 Injured       13777            8107            58.8\n3 No Injury     17242            9878            57.3\n\n\nCode\n# TRAV_SP seems to be correlated with INJ_SEV -- means TRAV_SP is likely MAR \n\ncar_crash_usa %&gt;%\n  mutate(Speed_Status = ifelse(is.na(TRAV_SP), \"Missing\", \"Known\")) %&gt;%\n  ggplot(aes(x = Speed_Status, fill = INJ_SEV)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Are Fatalities Hidden in the Missing Data?\",\n       y = \"Proportion of Crashes\",\n       x = \"Is Speed Recorded?\") +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nExploration of the TRAV_SP variable suggests a non-random missingness pattern that is strongly correlated with ‘Injury Severity.’ Specifically, the data suggests that fatal outcomes are disproportionately associated with missing speed values. This informative missingness may be attributed to situational constraints at the crash scene, such as extensive vehicle damage preventing post-crash speed assessment or emergency life-saving efforts taking precedence over administrative data collection. To preserve this predictive signal, we opted for a categorical binning strategy, treating ‘Unknown’ as a distinct and meaningful level rather than imputing these values.\n\n\nVSPD_LIM\nAlthough ‘Speed Limit’ data was missing for 3% of observations, these values are logically deducible from the surrounding context of the crash. By leveraging the strong correlation between road type and state regulations on speed limts, a kNN imputation strategy was implemented. This approach allows the model to estimate missing speed limits by identifying similar road segments within the same jurisdiction.\n\n\nCode\n# lets explore the missingness structure of VSPD_LIM: with INJ_SEV\ncar_crash_usa %&gt;%\n  group_by(ROUTE) %&gt;%\n  summarise(\n    total_obs = n(),\n    missing_trav_sp = sum(is.na(VSPD_LIM)),\n    percent_missing = mean(is.na(VSPD_LIM)) * 100\n  ) %&gt;%\n  arrange(desc(percent_missing))\n\n\n# A tibble: 13 × 4\n   ROUTE                   total_obs missing_trav_sp percent_missing\n   &lt;fct&gt;                       &lt;int&gt;           &lt;int&gt;           &lt;dbl&gt;\n 1 Parkway/Forest Route           11               2          18.2  \n 2 Off-Interstate Business        17               2          11.8  \n 3 BIA                            18               2          11.1  \n 4 Unknown                       739              57           7.71 \n 5 Not Signed                   4770             319           6.69 \n 6 Municipal                    4926             304           6.17 \n 7 County                       6020             323           5.37 \n 8 Township                      488              25           5.12 \n 9 US Highway                  10249             239           2.33 \n10 State Highway               17341             398           2.30 \n11 Interstate                   7595             106           1.40 \n12 Other                        3712              51           1.37 \n13 Secondary Route               711               1           0.141\n\n\n\n\nAGE\nPreliminary analysis indicates that ‘Age’ is non-randomly distributed across ‘Vehicle Type’ and ‘Sex.’ As a result we choose to use a kNN imputation approach to capture these localized demographic patterns, allowing the model to estimate missing ages by identifying clusters of drivers with similar characteristics.\n\n\nCode\n# correlation b/w age & vehicle type\np1 &lt;-car_crash_usa %&gt;% \n  filter(!is.na(AGE)) %&gt;% \n  ggplot(aes(x= AGE, y=BODYCLASS_SIMPLE, fill=BODYCLASS_SIMPLE)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of Age v. Vehicle Type\", \n       x= \"Age of Driver\", y= \"Vehicle Class\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\n\n# correlation b/w age & sex\np2 &lt;-car_crash_usa %&gt;% \n  filter(!is.na(AGE)) %&gt;% \n  ggplot(aes(x= AGE, y=SEX, fill=SEX)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of Age v. Sex\", \n       x= \"Age of Driver\", y= \"Sex of Driver\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\np1 + p2"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#train-test-split",
    "href": "projects/car_crash/car_crash.html#train-test-split",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Train-test split",
    "text": "Train-test split\nOur training split successfully preserves the original class distribution of INJ_SEV.\n\n\nCode\n# final dataset -- removing old/unused variables --------------------------\ncar_crash &lt;- car_crash_usa %&gt;% \n  select(INJ_SEV, VE_TOTAL, HOUR, DAY, ROUTE, HARM_EV, MAN_COLL_BIN, RUR_URB, LGT_SIMPLE,\n         WEATHER_SIMPLE, BODYCLASS_SIMPLE, AGE, SEX, REST_SIMPLE, AIRBAG_SIMPLE, WEIGHT,\n         TRAV_SP, VSPD_LIM, ROLLOVER, IMPACT1, DEFORMED, FIRE_EXP, VSURCOND, ALC_SIMPLE,\n         DRUGS, STATENAME, ST_CASE, WEEKDAY)\n# packages ----------------------------------------------------------------\nset.seed(123)\n\nlevels(car_crash$INJ_SEV) &lt;- make.names(levels(car_crash$INJ_SEV))\n\n# train-test split  -------------------------------------------------------\nsplit &lt;- group_initial_split(car_crash, group = ST_CASE, \n                             prop = 0.75)\ndata_train &lt;- training(split)\ndata_test  &lt;- testing(split)\n\n# Create Grouped Folds: this creates list of row indices where no ST_CASE is split across folds\nfolds_list &lt;- groupKFold(data_train$ST_CASE, k = 4)\nvalidation_index &lt;- list(Fold1 = folds_list[[1]]) # create our validation set\n\n# Pass these folds to trainControl\nctrl &lt;- trainControl(\n  index = validation_index,  # This forces caret to respect the groups\n  method = \"cv\",        # method is still validation set, created above\n  classProbs = TRUE,\n  savePredictions = \"final\"\n)\n\n# smaller sample (0.5) for kNN:\ndata_train_small &lt;- data_train %&gt;%\n  slice_sample(prop = 0.5, replace = FALSE)\n\n# CTRL for kNN sample:\nfolds_list_small &lt;- groupKFold(data_train_small$ST_CASE, k = 4)\nvalidation_index_small &lt;- list(Fold1 = folds_list_small[[1]])\n\nctrl_small &lt;- trainControl(\n  index = validation_index_small, # &lt;--- Uses the small indices\n  method = \"cv\",\n  classProbs = TRUE,\n  savePredictions = \"final\"\n)\n\n# sanity check: make sure split preserves our original balance\ndata_train %&gt;% \n  count(INJ_SEV) %&gt;% \n  mutate(prop = round(n/sum(n),4)*100)\n\n\n# A tibble: 3 × 3\n  INJ_SEV       n  prop\n  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;\n1 No.Injury 12941  30.5\n2 Injured   10358  24.4\n3 Dead      19149  45.1"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#feature-engineering",
    "href": "projects/car_crash/car_crash.html#feature-engineering",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nBetween imputation and standard preprocessing, we introduce two targeted feature, a light–weather interaction and a speeding indicator, to capture joint environmental risk and driver risk-taking behavior that are not represented by the raw variables alone.\n\nNew var: LGT_WEATHER INTERACTION\nTo capture joint environmental effects, we create an interaction feature combining simplified light and weather conditions (LGT_X_WEATHER). This allows the model to learn that certain combinations (e.g. darkness with precipitation) have different risk profiles than either factor alone. Rare light–weather combinations are grouped into a rare_combo category to reduce sparsity and improve model stability.\n\n\nCode\n# We manually replicate the Recipe logic here to inspect it\nviz_data &lt;- car_crash %&gt;%\n  # A. Re-create the Speeding & Interaction Logic\n  mutate(\n    # Re-create the interaction\n    LGT_X_WEATHER = paste(LGT_SIMPLE, WEATHER_SIMPLE, sep = \"__\"),\n    \n    # Re-create the lumping (using the same threshold as your recipe)\n    # Note: We use fct_lump_prop here to mimic step_other(threshold = 0.005)\n    LGT_X_WEATHER = fct_lump_prop(LGT_X_WEATHER, prop = 0.005, other_level = \"rare_combo\")\n  ) \n\n# 2. Prepare the summary stats\nplot_summary &lt;- viz_data %&gt;%\n  count(LGT_X_WEATHER, INJ_SEV) %&gt;%\n  group_by(LGT_X_WEATHER) %&gt;%\n  mutate(prop = n / sum(n)) %&gt;%\n  ungroup()\n\n# 3. Get the order for the plot (Most deadly -&gt; Least deadly)\norder_levels &lt;- plot_summary %&gt;%\n  filter(INJ_SEV == \"Dead\") %&gt;%\n  arrange(desc(prop)) %&gt;%\n  pull(LGT_X_WEATHER)\n\n# 4. Plot\nplot_summary %&gt;%\n  mutate(LGT_X_WEATHER = factor(LGT_X_WEATHER, levels = order_levels)) %&gt;%\n  ggplot(aes(x = LGT_X_WEATHER, y = prop, fill = INJ_SEV)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Injury Severity by Light/Weather Interaction\",\n    subtitle = \"Verifying the 'rare_combo' binning\",\n    x = NULL,\n    y = \"Proportion\"\n  ) +\n  theme(plot.subtitle = element_text(hjust = 0.5),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThe Light × Weather interaction reveals substantial heterogeneity in injury severity across environmental condition pairings, without a clear monotonic ordering. Notably, some dark but well-lit conditions show lower fatality shares, suggesting that roadway lighting and potential behavioral responses, such as drivers reducing speed or increasing caution in perceived high-risk conditions, may mitigate injury severity. These patterns support modeling Light and Weather jointly via an interaction term, rather than imposing a single ordered “danger” index that the data do not clearly support.\n\n\nNew var: SPEEDING\nSpeeding is a proxy for Risk Taking. A person doing 40 in a 25 zone is likely aggressive, distracted, or reckless. This variable captures the psychology of the driver, which is a different predictor than just the force of impact. We create this dummy variable before we decide to bin the TRAV_SP, since we will drop our original TRAV_SP variable once we bin it into categories.\n\n\nCode\n# --- Create temporary data for plotting ---\nviz_data_speeding &lt;- car_crash %&gt;%\n  mutate(\n    # Replicate the logic: If Speed &gt; Limit = Yes, otherwise No\n    SPEEDING = case_when(\n      TRAV_SP &gt; VSPD_LIM ~ \"Yes\",\n      TRUE ~ \"No\" # This catches NAs (Unknowns) and marks them as No\n    )\n  )\n\n# --- Check the distribution ---\nviz_data_speeding %&gt;%\n  count(SPEEDING) %&gt;%\n  mutate(prop = round(n / sum(n), 4) * 100)\n\n\n# A tibble: 2 × 3\n  SPEEDING     n  prop\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n1 No       49755  87.9\n2 Yes       6842  12.1\n\n\nCode\n# --- Visualize Impact on Severity  ---\n# This answers: \"Are speeders more likely to die?\"\nviz_data_speeding %&gt;%\n  filter(!is.na(INJ_SEV)) %&gt;% \n  ggplot(aes(x = SPEEDING, fill = INJ_SEV)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_brewer(palette = \"Reds\") + \n  labs(\n    title = \"Does Speeding Increase Fatality Risk?\",\n    x = \"Is Speeding?\",\n    y = \"Proportion of Crashes\",\n    fill = \"Severity\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nTRAV_SP\nThe transformation of TRAV_SP from a continuous numerical variable into ordered categorical bins allows for a clearer visualization of the risk profile. As illustrated in the distribution, there is a distinct positive correlation between higher speed cohorts and the proportion of fatal outcomes. Notably, the ‘Unknown’ category represents a significant portion of severe crashes, validating our decision to treat missingness as a distinct predictive feature rather than imputing it. This confirms that the absence of speed data is not random, but rather a characteristic of high-impact collisions where data collection was likely compromised.\n\n\nCode\nviz_data_speed &lt;- car_crash %&gt;%\n  mutate(\n    # Replicate the logic exactly from recipe\n    SPEED_CATEGORY = case_when(\n      is.na(TRAV_SP) ~ \"Unknown\",\n      TRAV_SP &lt; 10 ~ \"Stopped/Crawling (&lt;10)\",\n      TRAV_SP &gt;= 10 & TRAV_SP &lt; 30 ~ \"Low Speed (10-29)\",\n      TRAV_SP &gt;= 30 & TRAV_SP &lt; 55 ~ \"Medium Speed (30-54)\",\n      TRAV_SP &gt;= 55 & TRAV_SP &lt; 80 ~ \"High Speed (55-80)\",\n      TRAV_SP &gt;= 80 ~ \"Extreme Speed (80+)\",\n      TRUE ~ \"Unknown\"\n    ),\n    # Force the order of the bars (Ordinal Factor)\n    SPEED_CATEGORY = factor(SPEED_CATEGORY, \n                            levels = c(\"Unknown\", \"Stopped/Crawling (&lt;10)\", \n                                       \"Low Speed (10-29)\", \"Medium Speed (30-54)\", \n                                       \"High Speed (55-80)\", \"Extreme Speed (80+)\"))\n  )\n\n# --- Visualize Impact on Severity ---\nviz_data_speed %&gt;%\n  filter(!is.na(INJ_SEV)) %&gt;% \n  ggplot(aes(x = SPEED_CATEGORY, fill = INJ_SEV)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_brewer(palette = \"Reds\") + \n  labs(\n    title = \"Impact of Speed on Injury Severity\",\n    x = \"Speed Category\",\n    y = \"Proportion of Crashes\",\n    fill = \"Severity\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#multiclass-modeling",
    "href": "projects/car_crash/car_crash.html#multiclass-modeling",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "6.1 Multiclass Modeling",
    "text": "6.1 Multiclass Modeling\n\nMultinomial Logit (baseline)\nThe multinomial logistic regression serves as a natural baseline model. The confusion matrix shows a clear and consistent pattern: “No Injury” and “Dead” are predicted relatively well, while “Injured” is frequently confused with both neighboring classes. This indicates that extreme outcomes are easier to separate, whereas intermediate injury severity is more heterogeneous. Overall accuracy is moderate, but the model provides a transparent benchmark for understanding the structure of misclassification in the data.\n\n\nCode\nset.seed(123)\n# Caret method \"multinom\" uses the 'nnet' package\nfit_mlogit &lt;- train(crash_rec, data = data_train, \n                    method = \"multinom\", \n                    trControl = ctrl, \n                    trace = FALSE) # Suppress iteration logs\n\n# --- Predictions ---\npred_class_mlogit &lt;- predict(fit_mlogit, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_mlogit &lt;- confusionMatrix(pred_class_mlogit, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_mlogit &lt;- cm_mlogit$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_mlogit &lt;- mean(recall_mlogit, na.rm = TRUE)\n\nplot_heatmap(data_test$INJ_SEV, pred_class_mlogit, \"Multinomial Logit\")\n\n\n\n\n\n\n\n\n\n\n\nLASSO\nCompared to the baseline logit, the lasso model achieves slightly higher accuracy, mainly by making more confident predictions for the dominant classes. However, the overall error structure remains very similar. Performance on the “Injured” class does not improve meaningfully, suggesting that regularization helps stabilize predictions but does not fundamentally change class separability. Notice that across all three outcomes, Lasso keeps all of the variables. This suggests that each variable contains some information relevant to the predictor. As we can see, the lambda that minimizes the misclassification rate is lambda =0, which is our baseline linear model without any penalty. This suggests that the additional bias introduced via penalized regression actually does not reduce the variance enough to justify its usage versus a multinomial logistic regression\n\n\nCode\n# Define Grid for Lambda (Regularization Strength)\nlasso_grid &lt;- expand.grid(alpha = 1, lambda = seq(0.0001, 0.1, length = 20))\n\nset.seed(123)\nfit_lasso &lt;- train(crash_rec, data = data_train,\n                   method = \"glmnet\",\n                   trControl = ctrl,\n                   tuneGrid = lasso_grid,\n                   family = \"multinomial\") \n\n# --- Predictions ---\npred_class_lasso &lt;- predict(fit_lasso, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_lasso &lt;- confusionMatrix(pred_class_lasso, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_lasso &lt;- cm_lasso$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_lasso &lt;- mean(recall_lasso, na.rm = TRUE)\n\n# See which variables are shrunk to zero globally (for all 3 categories)\nlasso_coefs_list &lt;- coef(fit_lasso$finalModel, s = fit_lasso$bestTune$lambda)\n\nglobal_coef_matrix &lt;- do.call(cbind, lapply(lasso_coefs_list, as.matrix))\n\nis_dropped &lt;- rowSums(abs(global_coef_matrix)) == 0\n\ndropped_globally &lt;- rownames(global_coef_matrix)[is_dropped]\ndropped_globally &lt;- dropped_globally[dropped_globally != \"(Intercept)\"]\n\nkept_globally &lt;- rownames(global_coef_matrix)[!is_dropped]\nkept_globally &lt;- kept_globally[kept_globally != \"(Intercept)\"]\n\n# --- Results Summary ---\ncat(\"--- LASSO GLOBAL FEATURE SELECTION ---\\n\")\n\n\n--- LASSO GLOBAL FEATURE SELECTION ---\n\n\nCode\ncat(\"Total Variables Provided: \", nrow(global_coef_matrix) - 1, \"\\n\")\n\n\nTotal Variables Provided:  60 \n\n\nCode\ncat(\"Variables Kept:           \", length(kept_globally), \"\\n\")\n\n\nVariables Kept:            60 \n\n\nCode\ncat(\"Variables Dropped:        \", length(dropped_globally), \"\\n\\n\")\n\n\nVariables Dropped:         0 \n\n\nCode\n# Plot Error vs Lambda\np1 &lt;- ggplot(fit_lasso) + \n      labs(title = \"Lambda Tuning\",\n           subtitle = paste(\"Optimal Lambda:\", round(fit_lasso$bestTune$lambda, 4))) +\n      theme_minimal() +\n      theme(plot.title = element_text(hjust=0.5),\n            plot.subtitle = element_text(hjust = 0.5))\n# Confusion Matrix\np2 &lt;- plot_heatmap(data_test$INJ_SEV, pred_class_lasso, \"LASSO\")\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nRidge\nRidge regression performs very similarly to lasso. Differences in accuracy are marginal, and the confusion matrix closely mirrors that of the multinomial logit. Ridge tends to distribute weight more evenly across predictors, but this does not translate into a clear advantage for predicting intermediate injury severity.\n\n\nCode\n# Define Grid for Lambda\nridge_grid &lt;- expand.grid(alpha = 0, lambda = seq(0.0001, 0.1, length = 20))\n\nset.seed(123)\nfit_ridge &lt;- train(crash_rec, data = data_train,\n                   method = \"glmnet\",\n                   trControl = ctrl,\n                   tuneGrid = ridge_grid,\n                   family = \"multinomial\")\n\n# --- Predictions ---\npred_class_ridge &lt;- predict(fit_ridge, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_ridge &lt;- confusionMatrix(pred_class_ridge, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_ridge &lt;- cm_ridge$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_ridge &lt;- mean(recall_ridge, na.rm = TRUE)\n\n\np1 &lt;- ggplot(fit_ridge) + \n      labs(title = \"Lambda Tuning\",\n           subtitle = paste(\"Optimal Lambda:\", round(fit_ridge$bestTune$lambda, 4))) +\n      theme_minimal() +\n      theme(plot.title = element_text(hjust=0.5),\n            plot.subtitle = element_text(hjust = 0.5))\n# Confusion Matrix\np2 &lt;- plot_heatmap(data_test$INJ_SEV, pred_class_ridge, \"Ridge\")\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nkNN\nkNN shows lower overall accuracy compared to the linear models. It performs worse in distinguishing between injury categories, particularly for the “Dead” class, indicating sensitivity to noise and overlapping feature space. This suggests that distance-based similarity alone is insufficient to capture the complexity of injury severity patterns in the data. Note that for kNN, we only use a subsample of our training date (50%) for computational limits, since kNN computes euclidean distances between points. We still use the same test-data to compare our results, giving a fair comparison between the rest of our models.\n\n\nCode\n# Define Grid for k\nknn_grid &lt;- expand.grid(k = seq(3, 21, by = 2))\n\nset.seed(123)\nfit_knn &lt;- train(crash_rec, data = data_train_small,\n                 method = \"knn\",\n                 trControl = ctrl_small,\n                 tuneGrid = knn_grid)\n\n# --- Predictions ---\npred_class_knn &lt;- predict(fit_knn, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_knn &lt;- confusionMatrix(pred_class_knn, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_knn &lt;- cm_knn$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_knn &lt;- mean(recall_knn, na.rm = TRUE)\n\n\n# Plot k vs Accuracy\np1 &lt;- ggplot(fit_knn) + \n      labs(title = \"k-NN Parameter Tuning\", \n           subtitle = paste(\"Optimal k =\", fit_knn$bestTune$k)) +\n      theme_minimal() +\n      theme(plot.title = element_text(hjust=0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n# confusion matrix\np2 &lt;- plot_heatmap(data_test$INJ_SEV, pred_class_knn, paste(\"kNN (k=\", fit_knn$bestTune$k, \")\"))\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nRandom Forests\nThe random forest does not substantially outperform simpler models. While it captures some nonlinear relationships, its confusion matrix shows the same dominant misclassification pattern, especially for the “Injured” class. Gains over linear models are limited, indicating that higher model complexity does not unlock significantly more predictive signal. We notice that there seems to be a flattening after ~60 trees, so we set our ntree parameter to 100 since there isn’t a noticable improvement in performance after this point.\n\n\nCode\n# Note: 'mtry' is the main parameter to tune.\nrf_grid &lt;- expand.grid(mtry = c(2, 5, 10, floor(sqrt(ncol(data_train)))))\n\nset.seed(123)\nfit_rf &lt;- train(crash_rec, data = data_train,\n                method = \"rf\", \n                trControl = ctrl,\n                tuneGrid = rf_grid,\n                ntree = 100,\n                importance = TRUE) \n\n\n# --- Diagnostics ---\n# OOB Error Plot\noob_data &lt;- as.data.frame(fit_rf$finalModel$err.rate) %&gt;%\n  mutate(Trees = row_number()) %&gt;%\n  pivot_longer(cols = -Trees, names_to = \"Error_Type\", values_to = \"Error_Rate\")\n\nggplot(oob_data, aes(x = Trees, y = Error_Rate, color = Error_Type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"OOB Error vs Number of Trees\",\n    y = \"Classification Error\",\n    x = \"Number of Trees\",\n    color = \"Legend\"\n  ) +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nCode\n# --- Predictions ---\npred_class_rf &lt;- predict(fit_rf, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_rf &lt;- confusionMatrix(pred_class_rf, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_rf &lt;- cm_rf$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_rf &lt;- mean(recall_rf, na.rm = TRUE)\n\nplot_heatmap(data_test$INJ_SEV, pred_class_rf, \"Random Forest\")"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#results",
    "href": "projects/car_crash/car_crash.html#results",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Results",
    "text": "Results\n\nBalanced Accuracy.\nBalanced accuracy measures performance by first calculating how well the model predicts each injury category separately and then averaging these results. Unlike overall accuracy, it gives equal importance to all classes, which makes it a more truthful measure when some outcomes occur much more frequently than others, as is the case for injury severity. Although the injury severity classes are unevenly distributed, balanced accuracy closely tracks overall accuracy across all models. This indicates that higher accuracy is not achieved by favoring the most common outcomes, but reflects broadly consistent performance across injury categories. In practice, this confirms that differences between models are mainly due to changes in prediction confidence rather than shifts in how errors are distributed across severity levels.\n\n\nCode\n# Create a tidy table of results\nresults_table &lt;- tibble(\n  model = c(\"mLogit\", \"Lasso\", \"Ridge\", \"kNN\", \"RF\"),\n  \n  # Proportional Accuracy\n  Accuracy = c(\n    cm_mlogit$overall[\"Accuracy\"], \n    cm_lasso$overall[\"Accuracy\"],\n    cm_ridge$overall[\"Accuracy\"], \n    cm_knn$overall[\"Accuracy\"],  \n    cm_rf$overall[\"Accuracy\"]    \n  ),\n  \n  # Balanced Accuracy\n  Balanced = c(\n    balanced_acc_mlogit, \n    balanced_acc_lasso,\n    balanced_acc_ridge, \n    balanced_acc_knn,  \n    balanced_acc_rf\n  )\n)\n\nresults_table %&gt;%\n  pivot_longer(-model, names_to = \"metric\", values_to = \"value\") %&gt;%\n  ggplot(aes(x = reorder(model, value), y = value, fill = model)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  scale_y_continuous(labels = scales::percent,\n                     expand = expansion(mult = c(0, 0.15))) +\n  geom_text(aes(label = scales::percent(value, accuracy = 0.1)), \n            vjust = -0.5,\n            size = 3.5) + \n  facet_wrap(~metric, scales = \"free_y\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))+\n  labs(x = NULL, y = \"Score\", title = \"Model Comparison: Accuracy vs Balanced Accuracy\")\n\n\n\n\n\n\n\n\n\n\n\nOverall comparison and conclusions\nAcross all models, confusion matrices are remarkably similar. Extreme outcomes (“No Injury” and “Dead”) are consistently predicted better than intermediate injuries, which remain difficult to classify. More complex models do not meaningfully change this pattern, suggesting that limitations are driven primarily by data structure rather than modeling technique. Regularized linear models offer a strong balance between performance, stability, and interpretability, while additional complexity yields diminishing returns."
  },
  {
    "objectID": "projects/car_crash/car_crash.html#upsampling",
    "href": "projects/car_crash/car_crash.html#upsampling",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "6.2 Upsampling",
    "text": "6.2 Upsampling\nBecause injury severity outcomes are unevenly distributed, models may become biased toward predicting the more frequent classes, potentially underperforming on less common outcomes. To assess whether rebalancing the data can reduce this bias and improve performance, we apply upsampling to the training data by increasing the representation of underrepresented injury categories. We focus this analysis on lasso regression and random forest, which represent our strongest linear and non-parametric models, respectively. Although ridge regression achieved comparable or slightly better performance, lasso was chosen to maintain consistency in variable selection and sparsity across models. This approach allows us to assess whether class imbalance, rather than intrinsic overlap between injury severities, limits model performance.\n\n\nCode\n# Create a NEW recipe based on the old one\ncrash_rec_balanced &lt;- crash_rec %&gt;% \n  step_upsample(INJ_SEV, over_ratio = 1) \n\n# Check to ensure the step was added\n# print(crash_rec_balanced)\nbalanced_data &lt;- prep(crash_rec_balanced) %&gt;% \n  juice()\n\n# 2. Check the counts with a table: even split\ntable(balanced_data$INJ_SEV)\n\n\n\nNo.Injury   Injured      Dead \n    19149     19149     19149 \n\n\n\nLASSO\nAfter applying upsampling, the lasso model shows a modest increase in recall for the intermediate “Injured” class, indicating that the model becomes more sensitive to less frequent outcomes. However, this comes at the cost of reduced precision and recall for the extreme classes, particularly “No Injury” and “Dead”. The overall confusion pattern remains largely unchanged, suggesting that upsampling alters the model’s prediction balance rather than fundamentally improving class separability. Here we notice that Lasso does not drop any variables once again.\n\n\nCode\n# New Model (Balanced)\nfit_lasso_balanced &lt;- train(crash_rec_balanced, \n                            data = data_train,\n                   method = \"glmnet\",\n                   trControl = ctrl,\n                   tuneGrid = lasso_grid,\n                   family = \"multinomial\") \n\n# --- Predictions ---\npred_class_lasso_balanced &lt;- predict(fit_lasso_balanced, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_lasso_balanced &lt;- confusionMatrix(pred_class_lasso_balanced, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_lasso_balanced &lt;- cm_lasso_balanced$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_lasso_balanced &lt;- mean(recall_lasso_balanced, na.rm = TRUE)\n\n# See which variables are shrunk to zero globally (for all 3 categories)\nlasso_coefs_list_balanced &lt;- coef(fit_lasso_balanced$finalModel, s = fit_lasso_balanced$bestTune$lambda)\n\nglobal_coef_matrix_balanced &lt;- do.call(cbind, lapply(lasso_coefs_list_balanced, as.matrix))\n\nis_dropped &lt;- rowSums(abs(global_coef_matrix_balanced)) == 0\n\ndropped_globally &lt;- rownames(global_coef_matrix_balanced)[is_dropped]\ndropped_globally &lt;- dropped_globally[dropped_globally != \"(Intercept)\"]\n\nkept_globally &lt;- rownames(global_coef_matrix_balanced)[!is_dropped]\nkept_globally &lt;- kept_globally[kept_globally != \"(Intercept)\"]\n\n# --- Results Summary ---\ncat(\"--- LASSO GLOBAL FEATURE SELECTION ---\\n\")\n\n\n--- LASSO GLOBAL FEATURE SELECTION ---\n\n\nCode\ncat(\"Total Variables Provided: \", nrow(global_coef_matrix_balanced) - 1, \"\\n\")\n\n\nTotal Variables Provided:  60 \n\n\nCode\ncat(\"Variables Kept:           \", length(kept_globally), \"\\n\")\n\n\nVariables Kept:            60 \n\n\nCode\ncat(\"Variables Dropped:        \", length(dropped_globally), \"\\n\\n\")\n\n\nVariables Dropped:         0 \n\n\nCode\n# Plot Error vs Lambda\nggplot(fit_lasso_balanced) + \n      labs(title = \"Lambda Tuning\",\n           subtitle = paste(\"Optimal Lambda:\", round(fit_lasso_balanced$bestTune$lambda, 4))) +\n      theme_minimal() +\n      theme(plot.title = element_text(hjust=0.5),\n            plot.subtitle = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nCode\n# Confusion Matrix\nplot_heatmap(data_test$INJ_SEV, pred_class_lasso_balanced, \"LASSO\")\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest\nFor the random forest, upsampling leads to similar trade-offs. While predictions for the intermediate injury category improve slightly, performance for the extreme outcomes deteriorates. The confusion matrix indicates that upsampling increases uncertainty in cases that were previously classified with high confidence. Overall, the structure of errors remains consistent with the non-upsampled model.\n\n\nCode\n# New Model (Balanced)\nfit_rf_balanced &lt;- train(crash_rec_balanced, data = data_train,\n                method = \"rf\", \n                trControl = ctrl,\n                tuneGrid = rf_grid,\n                ntree = 100,\n                importance = TRUE) \n\n\n# --- Diagnostics ---\n# 1. OOB Error Plot\noob_data_balanced &lt;- as.data.frame(fit_rf_balanced$finalModel$err.rate) %&gt;%\n  mutate(Trees = row_number()) %&gt;%\n  pivot_longer(cols = -Trees, names_to = \"Error_Type\", values_to = \"Error_Rate\")\n\nggplot(oob_data_balanced, aes(x = Trees, y = Error_Rate, color = Error_Type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"OOB Error vs Number of Trees\",\n    y = \"Classification Error\",\n    x = \"Number of Trees\",\n    color = \"Legend\"\n  ) +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nCode\n# --- Predictions ---\npred_class_rf_balanced &lt;- predict(fit_rf_balanced, newdata = data_test)\n\n# --- Confusion Matrix & Heatmap ---\ncm_rf_balanced &lt;- confusionMatrix(pred_class_rf_balanced, data_test$INJ_SEV)\n\n# Per-class recall (sensitivity)\nrecall_rf_balanced &lt;- cm_rf_balanced$byClass[, \"Sensitivity\"]\n\n# Macro-averaged balanced accuracy\nbalanced_acc_rf_balanced &lt;- mean(recall_rf_balanced, na.rm = TRUE)\n\nplot_heatmap(data_test$INJ_SEV, pred_class_rf_balanced, \"Random Forest\")"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#results-1",
    "href": "projects/car_crash/car_crash.html#results-1",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Results",
    "text": "Results\n\nAccuracy vs. balanced accuracy\nDespite rebalancing the training data, accuracy and balanced accuracy remain closely aligned. This suggests that upsampling does not lead to a more equitable performance across classes, and that gains in minority-class recall are offset by losses elsewhere. Balanced accuracy therefore confirms that upsampling does not yield a net improvement in classification quality.\n\n\nCode\nacc_lasso &lt;- cm_lasso$overall[\"Accuracy\"]\nacc_rf    &lt;- cm_rf$overall[\"Accuracy\"]\nacc_lasso_bal &lt;- cm_lasso_balanced$overall[\"Accuracy\"]\nacc_rf_bal    &lt;- cm_rf_balanced$overall[\"Accuracy\"]\n\ntibble(\n  model = c(\"Lasso (Unbalanced)\", \"Lasso (Balanced)\", \n            \"RF (Unbalanced)\", \"RF (Balanced)\"),\n  Accuracy = c(acc_lasso, acc_lasso_bal, \n               acc_rf, acc_rf_bal)) %&gt;%\n  mutate(\n    Algorithm = case_when(\n      grepl(\"Lasso\", model) ~ \"Lasso\",\n      grepl(\"RF\", model)    ~ \"Random Forest\"\n    ),\n    Strategy = case_when(\n      grepl(\"Unbalanced\", model) ~ \"Unbalanced Data\",\n      TRUE                       ~ \"Balanced Data\"\n    ), Strategy = factor(Strategy, levels = c(\"Unbalanced Data\", \"Balanced Data\"))\n  ) %&gt;%\n  \n  ggplot(aes(x = Algorithm, y = Accuracy, fill = Algorithm)) +\n  geom_bar(stat = \"identity\", width = 0.5, show.legend = FALSE) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  facet_wrap(~Strategy) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 1.05), expand = c(0,0)) +\n  \n  geom_text(aes(label = scales::percent(Accuracy, accuracy = 0.1)), \n            vjust = -0.5, \n            size = 3.5)+\n  theme_minimal(base_size = 14) + \n  theme(\n    panel.grid.major.x = element_blank(), \n    strip.text = element_text(face = \"bold\", size = 12),\n    plot.title = element_text(hjust=0.5)\n  ) +\n  labs(x = NULL, y = \"Accuracy Score\", \n       title = \"Model Accuracy: Balanced vs Unbalanced\")\n\n\n\n\n\n\n\n\n\n\n\nUpsampling conclusion\nAcross both lasso regression and random forest models, upsampling does not lead to a meaningful improvement in predictive performance in the multiclass injury severity setting. While sensitivity to the intermediate “Injured” category increases slightly, this comes at the expense of reduced performance for the more clearly separable outcomes (“No Injury” and “Dead”). Overall accuracy and balanced accuracy do not improve, indicating that upsampling primarily redistributes errors across classes rather than enhancing class separation. These results suggest that intrinsic overlap between injury severity categories, rather than class imbalance alone, is the primary limitation, and that maintaining the original data distribution yields more reliable generalization."
  },
  {
    "objectID": "projects/car_crash/car_crash.html#binary-outcome-fatal-vs.-non-fatal",
    "href": "projects/car_crash/car_crash.html#binary-outcome-fatal-vs.-non-fatal",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "6.3 Binary outcome: Fatal vs. Non-Fatal",
    "text": "6.3 Binary outcome: Fatal vs. Non-Fatal\nIn the multiclass setting, model performance was primarily limited by difficulty in separating the intermediate “Injured” category from adjacent severity levels. This middle category exhibited substantial overlap in characteristics with both non-injury and fatal outcomes, leading to persistent misclassification across models. To assess how model performance changes when the target separation is clearer, we reformulate the outcome as a binary variable distinguishing fatal versus non-fatal crashes. This transformation also naturally reduces class imbalance without relying on resampling techniques. As earlier experiments with upsampling did not improve performance and introduced trade-offs between classes, the binary framing allows us to evaluate model behavior under a more balanced outcome distribution while preserving the original data structure. As in the multiclass analysis, we focus on comparable linear and non-parametric models to assess whether clearer outcome definitions lead to improved discrimination and more meaningful differences between modeling approaches.\n\n\nCode\ncar_crash_binary &lt;- car_crash %&gt;% \n  mutate(INJ_SEV = case_when(\n    grepl(\"Dead\", INJ_SEV, ignore.case = TRUE) ~ \"Fatal\", \n    TRUE ~ \"Non_Fatal\"\n  )) %&gt;%\n  mutate(INJ_SEV = factor(INJ_SEV, levels = c(\"Non_Fatal\", \"Fatal\")))\n\n# check new balance: 55/45 split\ncar_crash_binary %&gt;% \n  count(INJ_SEV) %&gt;% \n  mutate(prop = round(n/sum(n),4)*100)\n\n\n# A tibble: 2 × 3\n  INJ_SEV       n  prop\n  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;\n1 Non_Fatal 31019  54.8\n2 Fatal     25578  45.2\n\n\nCode\nset.seed(123)\n\nlevels(car_crash_binary$INJ_SEV) &lt;- make.names(levels(car_crash_binary$INJ_SEV))\n\n# train-test split  -------------------------------------------------------\nsplit_binary &lt;- group_initial_split(car_crash_binary, group = ST_CASE, \n                             prop = 0.75)\ndata_train_binary &lt;- training(split_binary)\ndata_test_binary  &lt;- testing(split_binary)\n\n# small sample (50%) for kNN\ndata_train_binary_small &lt;- data_train_binary %&gt;%\n  slice_sample(prop = 0.5, replace = FALSE)\n\n# CTRL for kNN sample:\nfolds_list_small_binary &lt;- groupKFold(data_train_binary_small$ST_CASE, k = 4)\nvalidation_index_small_binary &lt;- list(Fold1 = folds_list_small_binary[[1]])\n\nctrl_binary_small &lt;- trainControl(\n  index = validation_index_small_binary, # &lt;--- Uses the small indices\n  method = \"cv\",\n  classProbs = TRUE,\n  savePredictions = \"final\"\n)\n\n# Create Grouped Folds: this creates list of row indices where no ST_CASE is split across folds\nfolds_list_binary &lt;- groupKFold(data_train_binary$ST_CASE, k = 4)\nvalidation_index_binary &lt;- list(Fold1 = folds_list_binary[[1]]) # create our validation set\n\n# Pass these folds to trainControl\nctrl_binary &lt;- trainControl(\n  index = validation_index_binary,  # This forces caret to respect the groups\n  method = \"cv\",        # method is still validation set, created above\n  classProbs = TRUE,\n  summaryFunction = twoClassSummary,\n  savePredictions = \"final\"\n)\n\n\n\n\nCode\n# recipe: leak-safe imputation -------------------------------------------\n\ncrash_rec_binary &lt;- recipe(INJ_SEV ~ ., data = data_train_binary) %&gt;%\n  # --- 1. CLEANING & IMPUTATION ---\n\n  # A. Fix Invalid Hours (99 -&gt; NA) so we can impute them\n  step_mutate(\n    HOUR = ifelse(HOUR == 99, NA, HOUR)\n  ) %&gt;%\n  \n  # B. Impute Missing Values (Now including HOUR)\n  step_impute_knn(VSPD_LIM, impute_with = imp_vars(STATENAME, ROUTE), neighbors = 5) %&gt;%\n  step_impute_knn(AGE, impute_with = imp_vars(BODYCLASS_SIMPLE, HOUR, SEX), \n                  neighbors = 5) %&gt;%\n  step_impute_median(HOUR) %&gt;%\n\n  # --- 2. FEATURE ENGINEERING ---\n  \n  # A. Cyclic Encoding for Time\n  step_mutate(\n    HOUR_SIN = sin(2 * pi * HOUR / 24),\n    HOUR_COS = cos(2 * pi * HOUR / 24)\n  ) %&gt;%\n  \n  # B. Create new vars: speeding flag, LGT_WEATHER interaction\n  step_mutate(\n    SPEEDING = case_when(\n      TRAV_SP &gt; VSPD_LIM ~ \"Yes\",\n      TRUE ~ \"No\" \n    ),\n    SPEEDING = factor(SPEEDING),\n\n    # Create Interaction String\n    LGT_X_WEATHER = paste(LGT_SIMPLE, WEATHER_SIMPLE, sep = \"__\")\n  ) %&gt;%\n    \n    # Lumping (Handling Rare Categories)\n  step_other(LGT_X_WEATHER, threshold = 0.005, other = \"rare_combo\") %&gt;%\n  \n  # --- C. TRAV_SP (Binning) ---\n  step_mutate(\n    SPEED_CATEGORY = case_when(\n      is.na(TRAV_SP) ~ \"Unknown\",\n      TRAV_SP &lt; 10 ~ \"Stopped/Crawling (&lt;10)\",\n      TRAV_SP &gt;= 10 & TRAV_SP &lt; 30 ~ \"Low Speed (10-29)\",\n      TRAV_SP &gt;= 30 & TRAV_SP &lt; 55 ~ \"Medium Speed (30-54)\",\n      TRAV_SP &gt;= 55 & TRAV_SP &lt; 80 ~ \"High Speed (55-80)\",\n      TRAV_SP &gt;= 80 ~ \"Extreme Speed (80+)\",\n      TRUE ~ \"Unknown\" # Catch-all just in case\n    ),    \n    SPEED_CATEGORY = factor(SPEED_CATEGORY, \n                            levels = c(\"Unknown\", \"Stopped/Crawling (&lt;10)\", \n                                       \"Low Speed (10-29)\", \"Medium Speed (30-54)\", \n                                       \"High Speed (55-80)\", \"Extreme Speed (80+)\"))\n  ) %&gt;%\n  step_rm(HOUR, TRAV_SP, STATENAME, ST_CASE) %&gt;% \n  \n  # --- D. Standard Pre-processing  ---\n  # Convert all other characters to factors (e.g., SEX, WEATHER)\n  step_string2factor(all_nominal_predictors(), -matches(\"SPEED_CATEGORY\")) %&gt;%\n  # Dummy encode everything (One-Hot Encoding)\n  step_dummy(all_nominal_predictors(), -all_outcomes()) %&gt;%\n  # Remove sparse and unbalanced predictors\n  step_nzv(all_predictors()) %&gt;%\n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors())\n\n\n# --- 4. Verify it works ---\n# crash_rec %&gt;% \n#    prep() %&gt;% \n#    bake(car_crash) \n\n\n\nLogit\nIn the binary setting, logistic regression shows a clear improvement relative to the multiclass case. The model achieves high sensitivity for non-fatal crashes, correctly identifying a large share of survivable outcomes, while maintaining reasonable sensitivity (recall) for fatal crashes. Compared to the three-class setting, where misclassification was driven by overlap with the intermediate “Injured” category, the binary formulation allows the model to focus on a single decision boundary. Although direct metric comparisons are limited, the confusion structure indicates fewer false positives for fatal outcomes and more stable classification overall.\n\n\nCode\nfit_logit &lt;- train(crash_rec_binary, \n                   data = data_train_binary, \n                    method = \"glmnet\", \n                    family = \"binomial\",\n                    trControl = ctrl_binary, \n                    metric = \"ROC\", \n                    trace = FALSE) \n\n# --- Predictions ---\npred_class_logit &lt;- predict(fit_logit, newdata = data_test_binary)\n\n# --- Confusion Matrix & Heatmap ---\ncm_logit &lt;- confusionMatrix(pred_class_logit, data_test_binary$INJ_SEV,\n                            positive = \"Fatal\")\n\nplot_heatmap(data_test_binary$INJ_SEV, pred_class_logit, \"Logit\")\n\n\n\n\n\n\n\n\n\nCode\n# Store ROC\npred_prob_logit &lt;- predict(fit_logit, newdata = data_test_binary, type = \"prob\")\nroc_logit &lt;- roc(data_test_binary$INJ_SEV, pred_prob_logit$Fatal)\n\n\n\n\nLASSO\nLasso regression performs similarly to the baseline logistic model, with slightly improved stability due to coefficient shrinkage. In the binary case, regularization helps reduce false positive predictions of fatal crashes, improving specificity for the non-fatal class while preserving sensitivity for fatalities. Compared to the multiclass setting, where lasso primarily increased confidence without altering recall patterns, the binary formulation allows sparsity to sharpen the trade-off between sensitivity and specificity more effectively.\n\n\nCode\n# Define Grid for Lambda (Regularization Strength)\nlasso_grid &lt;- expand.grid(alpha = 1, lambda = seq(0.0001, 0.1, length = 20))\n\nfit_lasso_binary &lt;- train(crash_rec_binary, data = data_train_binary,\n                   method = \"glmnet\",\n                   trControl = ctrl_binary,\n                   tuneGrid = lasso_grid,\n                   metric = \"ROC\",\n                   family = \"binomial\") \n# 1. Lasso Tuning Plot\np1 &lt;- ggplot(fit_lasso_binary) + \n      labs(title = \"Lambda Tuning\",\n           subtitle = paste(\"Best Lambda:\", round((fit_lasso_binary$bestTune$lambda), 3))) +\n      theme_minimal() +\n  theme(plot.subtitle = element_text(hjust = 0.5),\n        plot.title = element_text(hjust = 0.5))\n\n# 2. Coefficient Path plot\np2 &lt;- wrap_elements(full = ~{\n  mod &lt;- fit_lasso_binary$finalModel\n  plot(mod, xvar = \"lambda\", label = TRUE)\n  l_val &lt;- log(fit_lasso_binary$bestTune$lambda)\n  abline(v = l_val, col = \"red\", lty = 2, lwd = 2)\n})\n\np1 + p2\n\n\n\n\n\n\n\n\n\nCode\n# --- Predictions ---\npred_class_lasso_binary &lt;- predict(fit_lasso_binary, newdata = data_test_binary)\n\n# --- Confusion Matrix & Heatmap ---\ncm_lasso_binary &lt;- confusionMatrix(pred_class_lasso_binary, data_test_binary$INJ_SEV,\n                                   positive = \"Fatal\")\n\n# See how many variables are kept/dropped\nlasso_coefs_binary &lt;- as.matrix(coef(fit_lasso_binary$finalModel, s = fit_lasso_binary$bestTune$lambda))\n\nis_dropped &lt;- lasso_coefs_binary[, 1] == 0\n\ndropped_globally &lt;- rownames(lasso_coefs_binary)[is_dropped]\ndropped_globally &lt;- dropped_globally[dropped_globally != \"(Intercept)\"]\n\nkept_globally &lt;- rownames(lasso_coefs_binary)[!is_dropped]\nkept_globally &lt;- kept_globally[kept_globally != \"(Intercept)\"]\n\n# --- Results Summary ---\ncat(\"--- LASSO GLOBAL FEATURE SELECTION (BINARY) ---\\n\")\n\n\n--- LASSO GLOBAL FEATURE SELECTION (BINARY) ---\n\n\nCode\ncat(\"Total Variables Provided: \", nrow(lasso_coefs_binary) - 1, \"\\n\")\n\n\nTotal Variables Provided:  60 \n\n\nCode\ncat(\"Variables Kept:           \", length(kept_globally), \"\\n\")\n\n\nVariables Kept:            59 \n\n\nCode\ncat(\"Variables Dropped:        \", length(dropped_globally), \"\\n\\n\")\n\n\nVariables Dropped:         1 \n\n\nCode\n# confusion matrix\nplot_heatmap(data_test_binary$INJ_SEV, pred_class_lasso_binary, \"LASSO\")\n\n\n\n\n\n\n\n\n\nCode\n# Store ROC\npred_prob_lasso_binary &lt;- predict(fit_lasso_binary, newdata = data_test_binary, type = \"prob\")\nroc_lasso &lt;- roc(data_test_binary$INJ_SEV, pred_prob_lasso_binary$Fatal)\n\n\n\n\nRidge\nRidge regression delivers comparable performance to lasso, with balanced sensitivity across fatal and non-fatal outcomes. By retaining correlated predictors, ridge aggregates small effects that contribute to fatal risk, leading to stable recall without excessive false positives. As in the multiclass case, differences between linear models remain modest, but the clearer binary outcome allows their behavior to be interpreted more directly in terms of sensitivity and specificity.\n\n\nCode\n# Define Grid for Lambda\nridge_grid &lt;- expand.grid(alpha = 0, lambda = seq(0.0001, 0.1, length = 20))\n\nfit_ridge_binary &lt;- train(crash_rec_binary, \n                          data = data_train_binary,\n                   method = \"glmnet\",\n                   trControl = ctrl_binary,\n                   tuneGrid = ridge_grid,\n                   metric = \"ROC\",\n                   family = \"binomial\") \n\n# 1. Optimal Lambda Path\np1 &lt;- ggplot(fit_ridge_binary) + \n      labs(title = \"Lambda Tuning\") +\n      theme_minimal()\n\n# 2. Coefficient Path plot\np2 &lt;- wrap_elements(full = ~{\n  plot(fit_ridge_binary$finalModel, xvar = \"lambda\", label = TRUE)\n  # Add a vertical line for the optimal lambda\n  abline(v = log(fit_ridge_binary$bestTune$lambda), col = \"red\", lty = 2)\n})\np1 + p2\n\n\n\n\n\n\n\n\n\nCode\n# --- Predictions ---\npred_class_ridge_binary &lt;- predict(fit_ridge_binary, newdata = data_test_binary)\n\n# --- Confusion Matrix & Heatmap ---\ncm_ridge_binary &lt;- confusionMatrix(pred_class_ridge_binary, data_test_binary$INJ_SEV,\n                                   positive = \"Fatal\")\n\nplot_heatmap(data_test_binary$INJ_SEV, pred_class_ridge_binary, \"RIDGE\")\n\n\n\n\n\n\n\n\n\nCode\n# Store ROC\npred_prob_ridge_binary &lt;- predict(fit_ridge_binary, newdata = data_test_binary, type = \"prob\")\nroc_ridge &lt;- roc(data_test_binary$INJ_SEV, pred_prob_ridge_binary$Fatal)\n\n\n\n\nkNN\nkNN shows improved performance compared to its multiclass results but remains weaker than linear and tree-based models. While sensitivity for non-fatal crashes increases, the model still exhibits higher false negative rates for fatal outcomes, indicating limited ability to reliably detect death cases. This mirrors the multiclass setting, where local similarity struggled to separate overlapping injury categories, and suggests that distance-based methods remain sensitive to noise in high-dimensional feature space.\n\n\nCode\n# Define Grid for k\nknn_grid &lt;- expand.grid(k = seq(3, 21, by = 2))\n\nfit_knn_binary &lt;- train(crash_rec_binary, \n                        data = data_train_binary_small,\n                        method = \"knn\",\n                        trControl = ctrl_binary_small,\n                        metric = \"ROC\",\n                        tuneGrid = knn_grid)\n\n# --- Predictions ---\npred_class_knn_binary &lt;- predict(fit_knn_binary, newdata = data_test_binary)\n\n# --- Confusion Matrix & Heatmap ---\ncm_knn_binary &lt;- confusionMatrix(pred_class_knn_binary, data_test_binary$INJ_SEV,\n                                 positive = \"Fatal\")\n\n# Plot k vs Accuracy\np1 &lt;- ggplot(fit_knn_binary) + \n      labs(title = \"k-NN Parameter Tuning\", \n           subtitle = paste(\"Optimal k =\", fit_knn$bestTune$k)) +\n      theme_minimal() +\n      theme(plot.subtitle = element_text(hjust = 0.5),\n        plot.title = element_text(hjust = 0.5))\n# Confusion Matrix\np2 &lt;- plot_heatmap(data_test_binary$INJ_SEV, pred_class_knn_binary, \n                   paste(\"kNN (k=\", fit_knn_binary$bestTune$k, \")\"))\np1 + p2\n\n\n\n\n\n\n\n\n\nCode\n# Store ROC\npred_prob_knn_binary &lt;- predict(fit_knn_binary, newdata = data_test_binary, type = \"prob\")\nroc_knn &lt;- roc(data_test_binary$INJ_SEV, pred_prob_knn_binary$Fatal)\n\n\n\n\nRandom Forests\nThe random forest benefits more clearly from the binary outcome formulation. Compared to the multiclass case, the model achieves improved sensitivity for fatal crashes, indicating better detection of high-risk scenarios. However, gains are partially offset by a modest increase in false positives, reflecting a trade-off between sensitivity and specificity. While nonlinear interactions contribute more meaningfully in the binary setting, overall improvements over regularized linear models remain moderate.\n\n\nCode\n# Note: 'mtry' is the main parameter to tune.\nrf_grid &lt;- expand.grid(mtry = c(2, 5, 10, floor(sqrt(ncol(data_train_binary)))))\n\nfit_rf_binary &lt;- train(crash_rec_binary, data = data_train_binary,\n                method = \"rf\", \n                trControl = ctrl_binary,\n                tuneGrid = rf_grid,\n                ntree = 100,\n                metric = \"ROC\",\n                importance = TRUE) \n\n\n# --- Diagnostics ---\n# 1. OOB Error Plot\noob_data_binary &lt;- as.data.frame(fit_rf_binary$finalModel$err.rate) %&gt;%\n  mutate(Trees = row_number()) %&gt;%\n  pivot_longer(cols = -Trees, names_to = \"Error_Type\", values_to = \"Error_Rate\")\n\nggplot(oob_data_binary, aes(x = Trees, y = Error_Rate, color = Error_Type)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"OOB Error vs Number of Trees\",\n    y = \"Classification Error\",\n    x = \"Number of Trees\",\n    color = \"Legend\"\n  ) +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\nCode\n# --- Predictions ---\npred_class_rf_binary &lt;- predict(fit_rf_binary, newdata = data_test_binary)\n\n# --- Confusion Matrix & Heatmap ---\ncm_rf_binary &lt;- confusionMatrix(pred_class_rf_binary, data_test_binary$INJ_SEV,\n                                positive = \"Fatal\")\n\nplot_heatmap(data_test_binary$INJ_SEV, pred_class_rf_binary, \"Random Forest\")\n\n\n\n\n\n\n\n\n\nCode\n# Store ROC\npred_prob_rf_binary &lt;- predict(fit_rf_binary, newdata = data_test_binary, type = \"prob\")\nroc_rf &lt;- roc(data_test_binary$INJ_SEV, pred_prob_rf_binary$Fatal)"
  },
  {
    "objectID": "projects/car_crash/car_crash.html#comparing-binary-performances",
    "href": "projects/car_crash/car_crash.html#comparing-binary-performances",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "Comparing Binary Performances",
    "text": "Comparing Binary Performances\nAcross all models, the binary formulation enables clearer interpretation of performance in terms of sensitivity, specificity, and false positive/negative errors. Improvements relative to the multiclass setting are driven primarily by the removal of the ambiguous intermediate category, rather than by changes in model complexity. While direct metric comparisons are not appropriate, the binary results highlight how outcome definition influences achievable sensitivity for fatal crashes and overall classification stability.\n\n\nCode\n# 0. Misclassification Rates (Accuracy):\nmodel_comparison &lt;- data.frame(\n  Model = c(\"Logistic Regression\", \"Lasso\", \"Ridge\", \"k-NN\", \"Random Forest\"),\n  Accuracy = c(\n    cm_logit$overall[\"Accuracy\"],\n    cm_lasso_binary$overall[\"Accuracy\"],\n    cm_ridge_binary$overall[\"Accuracy\"],\n    cm_knn_binary$overall[\"Accuracy\"],\n    cm_rf_binary$overall[\"Accuracy\"]\n  ),\n  Balanced_Accuracy = c(\n    cm_logit$byClass[\"Balanced Accuracy\"],\n    cm_lasso_binary$byClass[\"Balanced Accuracy\"],\n    cm_ridge_binary$byClass[\"Balanced Accuracy\"],\n    cm_knn_binary$byClass[\"Balanced Accuracy\"],\n    cm_rf_binary$byClass[\"Balanced Accuracy\"]\n  )\n)\n\nmodel_summary_table &lt;- model_comparison %&gt;%\n  mutate(across(where(is.numeric), ~ round(., 3))) %&gt;%\n  arrange(desc(Accuracy))\n\nprint(\"--- Final Model Leaderboard (Misclassification Rate) ---\")\n\n\n[1] \"--- Final Model Leaderboard (Misclassification Rate) ---\"\n\n\nCode\nprint(model_summary_table)\n\n\n                Model Accuracy Balanced_Accuracy\n1       Random Forest    0.864             0.863\n2 Logistic Regression    0.853             0.851\n3               Lasso    0.853             0.851\n4               Ridge    0.848             0.845\n5                k-NN    0.819             0.812\n\n\nCode\n# 1. Gather all ROC objects into a list\nroc_list &lt;- list(\n  Logistic      = roc_logit,\n  Ridge         = roc_ridge,\n  Lasso         = roc_lasso,\n  kNN           = roc_knn,\n  RandomForest  = roc_rf\n)\n\n# 2. Extract AUC values\nauc_values &lt;- sapply(roc_list, function(x) as.numeric(auc(x)))\n\n# 3. Create a Data Frame\nauc_table &lt;- data.frame(\n  Model = names(auc_values),\n  AUC = round(auc_values, 4)\n)\n\n# 4. Sort by AUC (Descending)\nauc_table_sorted &lt;- auc_table %&gt;%\n  arrange(desc(AUC))\n\n# 5. Print the Clean Table\nprint(\"--- Final Model Leaderboard (AUC) ---\")\n\n\n[1] \"--- Final Model Leaderboard (AUC) ---\"\n\n\nCode\nprint(auc_table_sorted)\n\n\n                    Model    AUC\nRandomForest RandomForest 0.9372\nLogistic         Logistic 0.9308\nLasso               Lasso 0.9308\nRidge               Ridge 0.9286\nkNN                   kNN 0.9092\n\n\nCode\nggroc(roc_list, size = 1) +\n  geom_abline(slope = 1, intercept = 1, linetype = \"dashed\", color = \"grey\") +\n  labs(title = \"ROC Comparison\",\n       color = \"Models\")  +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nBinary outcome conclusion\nReformulating injury severity as a binary outcome (fatal vs. non-fatal) leads to clearer and more stable model performance across all approaches. By removing the ambiguous intermediate injury category, the classification task becomes structurally simpler, allowing models to focus on separating extreme outcomes rather than ranking overlapping severity levels. While direct metric comparisons with the three-class setting are limited, the binary results demonstrate consistently improved discrimination and more meaningful differences between models. Importantly, the naturally closer balance between fatal and non-fatal outcomes yields better performance without the need for resampling. In contrast to earlier upsampling experiments, where gains for minority outcomes were offset by losses elsewhere, the binary formulation improves performance without introducing artificial noise or redistributing errors across classes. This suggests that the primary limitation in the multiclass setting was not class imbalance alone, but intrinsic overlap between injury severity categories. Overall, the binary analysis shows that clearer outcome definitions and natural class balance are more effective than resampling techniques in improving predictive performance. The results highlight how outcome formulation plays a central role in achievable model accuracy and interpretability, and demonstrate that simplifying the target variable can reveal stronger and more reliable predictive signal than adjusting class proportions through upsampling."
  },
  {
    "objectID": "projects/car_crash/car_crash.html#variable-importance",
    "href": "projects/car_crash/car_crash.html#variable-importance",
    "title": "Modeling the Impact: When Data Hits Hard",
    "section": "6.4 Variable Importance",
    "text": "6.4 Variable Importance\nThe figure shows the most important predictors for lasso regression and random forest in the three-class injury severity setting. To allow comparison across models, variable importance scores were normalized within each model, benchmarking the most influential variable to one. This normalization makes relative importance comparable across fundamentally different modeling approaches.\nAcross both models, and consistently across alternative specifications (including undersampling and the binary outcome), a stable set of variables repeatedly emerges as influential, although their exact ranking varies. These variables can be grouped into a few key themes that appear decisive in determining crash severity.\nFirst, crash type and exposure play a central role. Variables capturing collisions with non-motorists, non-vehicle crashes, or motorcycles consistently rank among the most important predictors, reflecting the heightened vulnerability of certain road users. Second, occupant protection and vehicle safety indicators, such as restraint use, airbag deployment, and rollover involvement—are highly influential, highlighting the importance of protective mechanisms during a crash. Third, impact severity proxies, including vehicle deformation and the number of vehicles involved, contribute strongly, suggesting that crash force and complexity are key drivers of injury outcomes. Finally, behavioral risk factors, such as alcohol involvement and speeding, appear repeatedly, although their relative importance differs across models.\nAlthough these patterns suggest a coherent narrative linking vulnerability, protection, and crash dynamics to injury severity, interpretation is limited. Importance rankings vary across models due to differences in how predictors and interactions are handled, and reflect predictive relevance rather than causality.\nThe recurrence of similar variable groups across models nonetheless indicates robust underlying structure, while variation in rankings underscores that injury severity arises from multiple interacting factors rather than a single dominant driver.\n\n\nCode\nlasso_coefs_raw &lt;- coef(fit_lasso$finalModel, s = fit_lasso$bestTune$lambda)\nlasso_vi &lt;- do.call(rbind, lapply(names(lasso_coefs_raw), function(class_name) {\n  data.frame(\n    Variable = rownames(as.matrix(lasso_coefs_raw[[class_name]])),\n    Importance = as.vector(as.matrix(lasso_coefs_raw[[class_name]])),\n    Class = class_name\n  )\n})) %&gt;%\n  filter(Variable != \"(Intercept)\") %&gt;%\n  group_by(Variable) %&gt;%\n  summarize(Importance = mean(abs(Importance))) %&gt;%\n  mutate(Model = \"Lasso\")\n\n# --- 2. Extract Random Forest Importance ---\nrf_vi &lt;- vi(fit_rf$finalModel) %&gt;%\n  rename(Importance = Importance) %&gt;%\n  mutate(Model = \"Random Forest\")\n\n# --- 3. Combine and Normalize (0-100 scale) ---\n# We filter for the Top 20 variables from the Random Forest to keep the plot clean\ntop_vars &lt;- rf_vi %&gt;% arrange(desc(Importance)) %&gt;% head(15) %&gt;% pull(Variable)\n\ncombined_vi &lt;- bind_rows(lasso_vi, rf_vi) %&gt;%\n  filter(Variable %in% top_vars) %&gt;%\n  group_by(Model) %&gt;%\n  mutate(Norm_Importance = (Importance / max(Importance)) * 100) %&gt;%\n  ungroup()\n\n# --- 4. Generate the Comparison Plot ---\n# \nggplot(combined_vi, aes(x = Norm_Importance, \n                        y = reorder(Variable, Norm_Importance), \n                        fill = Model)) +\n  geom_col(position = position_dodge(width = 0.7), width = 0.6) +\n  scale_fill_manual(values = c(\"Random Forest\" = \"#1b9e77\", \"Lasso\" = \"#d95f02\")) +\n  labs(title = \"Model Comparison: Variable Importance\",\n       subtitle = \"Top 15 predictors (Normalized 0-100)\",\n       x = \"Importance Score (Normalized)\",\n       y = NULL) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.subtitle = element_text(hjust = 0.5),\n        plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Michael Fehl",
    "section": "",
    "text": "BSc in Economics from UNC Chapel Hill.\nMSc Economics Candidate @ Barcelona School of Economics\nCurrently, I am pursuing my Master’s in Economics at the Barcelona School of Economics. My research interests revolve around game theory, causal inference, public policy, and network analysis.\nI am passionate about applying econometric methods to real-world datasets to inform policy decisions and drive impactful change. I believe that through data, we can uncover hidden patterns and extract valuable insights that help us better understand and improve the world around us.\nBeyond core economics, I am also deeply interested in dynamic data visualizations and machine learning methods to enhance data interpretation and decision-making.\n\n\n\n\nThesis: Analyzing the effects of macro-level shocks on remittance transfers between the USA and Mexico, using Shift-Share Instrumental Variables methodology in Stata\nProject: Geospatial analysis of infrastructure growth: Visualizing spatial development patterns in emerging markets using R\nProject: Replicating Conway’s Game of Life & modeling partial equilibrium in a two-agent, two-good economy in MATLAB\nProject: Modeling information cascades and belief propagation through agent-based modeling in Python\n\n\n\n\n\nLanguages: R, Python, MATLAB, Stata\nTools: Quarto, SQL, LaTeX\n\n\n\n\n\nDevelopment Economics\nCausal Inference & Policy Evaluation\nNetworks, Crowds, and Strategic Interaction"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "Michael Fehl",
    "section": "",
    "text": "BSc in Economics from UNC Chapel Hill.\nMSc Economics Candidate @ Barcelona School of Economics\nCurrently, I am pursuing my Master’s in Economics at the Barcelona School of Economics. My research interests revolve around game theory, causal inference, public policy, and network analysis.\nI am passionate about applying econometric methods to real-world datasets to inform policy decisions and drive impactful change. I believe that through data, we can uncover hidden patterns and extract valuable insights that help us better understand and improve the world around us.\nBeyond core economics, I am also deeply interested in dynamic data visualizations and machine learning methods to enhance data interpretation and decision-making.\n\n\n\n\nThesis: Analyzing the effects of macro-level shocks on remittance transfers between the USA and Mexico, using Shift-Share Instrumental Variables methodology in Stata\nProject: Geospatial analysis of infrastructure growth: Visualizing spatial development patterns in emerging markets using R\nProject: Replicating Conway’s Game of Life & modeling partial equilibrium in a two-agent, two-good economy in MATLAB\nProject: Modeling information cascades and belief propagation through agent-based modeling in Python\n\n\n\n\n\nLanguages: R, Python, MATLAB, Stata\nTools: Quarto, SQL, LaTeX\n\n\n\n\n\nDevelopment Economics\nCausal Inference & Policy Evaluation\nNetworks, Crowds, and Strategic Interaction"
  },
  {
    "objectID": "projects/cascades/cascades.html",
    "href": "projects/cascades/cascades.html",
    "title": "cascades",
    "section": "",
    "text": "Introduction\n\nbackground\ngoals of the project\nconnection/difference from social contagions\nbasic structure\n\n\n\nTheoretical Framework\n\ndefining our framework (graph)\nSIR/SIS models\n\n\n\nSystem Architecture\n\nABM Design\nSQL Backend (manual design or downloaded somewhere?)\n\n\n\nCode\n# import libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\n\nSimulations\n\n\nCode\n# plot output example\nt = np.arange(0.0, 2.0, 0.01)\ns = 1 + np.sin(2 * np.pi * t)\n\nfig, ax = plt.subplots()\nax.plot(t, s)\n\nax.set(xlabel='time (s)', ylabel='voltage (mV)',\n       title='super basic plot')\nax.grid()\n\n\n\n\n\n\n\n\n\n\n\nResults & Data Analysis\n\n\nDiscussion: Policy & Intervention\n\n\nConclusion\n\nfindings from our project, what we learned\nbig picture\nfuture extensions"
  },
  {
    "objectID": "projects/games/games.html#intro",
    "href": "projects/games/games.html#intro",
    "title": "Steady States: Finding Balance in a Risky World",
    "section": "Intro",
    "text": "Intro\nbackground (what)\nmotivation (why)\nproject structure\ngoals of this project"
  },
  {
    "objectID": "projects/games/games.html#game-of-life",
    "href": "projects/games/games.html#game-of-life",
    "title": "Steady States: Finding Balance in a Risky World",
    "section": "Game of Life",
    "text": "Game of Life\n\n\nCode\n% set our global plot options: \"light mode\"\nset(groot, 'defaultFigureColor', 'w');\nset(groot, 'defaultAxesColor', 'w');\nset(groot, 'defaultAxesXColor', [0.1 0.1 0.1]);\nset(groot, 'defaultAxesYColor', [0.1 0.1 0.1]);\nset(groot, 'defaultTextColor', 'k');\nset(groot, 'defaultLegendTextColor', 'k');   % k == black\nset(groot, 'defaultFigureInvertHardcopy', 'on');\n\n\n\n\nCode\n%%% Simulation Code %%%\n%----------------------\nclear\n\n% Task: build 1000 monte carlo simulations\n\nrng(14) % set seed\nsims = 1000; % num of sims\n\n% to create conways game of life, our universe is a matrix.\n% the non-zero elements are the population\n\nlife = zeros(4); % initalize our 4x4 grid of zeros\n\nrows = [1, 1, 2]; % set our agents\ncols = [1, 2, 2];\nidx = sub2ind(size(life), rows, cols);\nlife(idx) = 1;\n\n% visualize our non-zero points (agents)\nspy(life)\n\n\n\n\n\n\n\nCode\n% t = tiledlayout(1,3,'TileSpacing','Compact');\n%\n% nexttile\n% spy(life_initial); title('t=0')\n%\n% nexttile\n% spy(life_step1); title('t=1')\n%\n% nexttile\n% spy(life_final); title('t=end')\n%% example of combining graphs to help w/ flow"
  },
  {
    "objectID": "projects/games/games.html#general-competitive-equilibrium",
    "href": "projects/games/games.html#general-competitive-equilibrium",
    "title": "Steady States: Finding Balance in a Risky World",
    "section": "General Competitive Equilibrium",
    "text": "General Competitive Equilibrium"
  },
  {
    "objectID": "projects/games/games.html#extensions",
    "href": "projects/games/games.html#extensions",
    "title": "Steady States: Finding Balance in a Risky World",
    "section": "Extensions",
    "text": "Extensions\n\n\nn-Agent Economy\n\n\n\nNetwork w/ Intermediaries\n\n\n\nn-Good Economy (?)"
  },
  {
    "objectID": "projects/games/games.html#conclusion",
    "href": "projects/games/games.html#conclusion",
    "title": "Steady States: Finding Balance in a Risky World",
    "section": "Conclusion",
    "text": "Conclusion\nwhat we learned, confirmed, the things we cannot conclude (need more info), realism, where our models fail (or dont/cant account for), etc."
  }
]